<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MoE Backend Performance: CUTLASS vs TRT-LLM Complete Analysis</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Inter', 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, #0a0a0a 0%, #1a1a2e 100%);
            color: #ffffff;
            line-height: 1.6;
            padding: 20px;
            min-height: 100vh;
        }
        
        .container {
            max-width: 1400px;
            margin: 0 auto;
        }
        
        header {
            text-align: center;
            padding: 60px 20px;
            margin-bottom: 40px;
            position: relative;
        }
        
        header::before {
            content: "";
            position: absolute;
            top: 50%;
            left: 50%;
            width: 600px;
            height: 600px;
            background: radial-gradient(circle, rgba(94,92,230,0.1) 0%, transparent 70%);
            transform: translate(-50%, -50%);
            z-index: -1;
        }
        
        h1 {
            font-size: 3.5rem;
            font-weight: 700;
            margin-bottom: 1rem;
            background: linear-gradient(135deg, #5E5CE6 0%, #60a5fa 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            letter-spacing: -0.02em;
        }
        
        .subtitle {
            font-size: 1.3rem;
            color: #8E8E93;
            margin-bottom: 10px;
        }
        
        .dataset-tabs {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-bottom: 40px;
            flex-wrap: wrap;
        }
        
        .tab-button {
            padding: 12px 30px;
            background: #1C1C1E;
            border: 2px solid #2C2C2E;
            color: #8E8E93;
            border-radius: 12px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: 600;
            font-size: 1rem;
        }
        
        .tab-button:hover {
            border-color: #5E5CE6;
            transform: translateY(-2px);
        }
        
        .tab-button.active {
            background: linear-gradient(135deg, #5E5CE6 0%, #60a5fa 100%);
            color: #ffffff;
            border-color: transparent;
        }
        
        .dataset-content {
            display: none;
        }
        
        .dataset-content.active {
            display: block;
        }

        /* Command Section Styles */
        .command-section {
            background: rgba(10,10,10,0.8);
            border: 1px solid #1C1C1E;
            border-radius: 16px;
            padding: 30px;
            margin: 40px 0;
            backdrop-filter: blur(10px);
        }
        
        .section-header {
            display: flex;
            align-items: center;
            cursor: pointer;
            user-select: none;
            gap: 15px;
        }
        
        .section-header:hover {
            opacity: 0.8;
        }
        
        .toggle-icon {
            display: inline-flex;
            align-items: center;
            justify-content: center;
            width: 24px;
            height: 24px;
            background: #5E5CE6;
            border-radius: 6px;
            transition: transform 0.3s ease;
            font-size: 0.9rem;
            flex-shrink: 0;
        }
        
        .toggle-icon.collapsed {
            transform: rotate(-90deg);
        }
        
        .command-section h2 {
            font-size: 1.5rem;
            color: #60a5fa;
            display: flex;
            align-items: center;
            gap: 10px;
            margin: 0;
        }
        
        .section-content {
            max-height: 4000px;
            overflow: hidden;
            transition: all 0.3s ease;
            margin-top: 20px;
        }
        
        .section-content.collapsed {
            max-height: 0;
            margin-top: 0;
            opacity: 0;
            visibility: hidden;
        }
        
        .code-block {
            background: #0a0a0a;
            border: 1px solid #2C2C2E;
            border-radius: 8px;
            padding: 20px;
            overflow-x: auto;
            position: relative;
            margin: 15px 0;
        }
        
        .code-block textarea {
            width: 100%;
            background: transparent;
            border: none;
            color: #10b981;
            font-family: 'Monaco', 'Courier New', monospace;
            font-size: 0.95rem;
            line-height: 1.6;
            resize: none;
            outline: none;
            overflow: hidden;
        }
        
        .code-block pre {
            margin: 0;
            white-space: pre;
            overflow-x: auto;
        }
        
        .code-block code {
            color: #10b981;
            font-family: 'Monaco', 'Courier New', monospace;
            font-size: 0.95rem;
            line-height: 1.6;
            white-space: pre;
            display: block;
        }
        
        .copy-button {
            position: absolute;
            top: 10px;
            right: 10px;
            padding: 8px 16px;
            background: #5E5CE6;
            color: #fff;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-size: 0.85rem;
            transition: all 0.3s ease;
            opacity: 0;
            z-index: 10;
        }
        
        .code-block:hover .copy-button {
            opacity: 1;
        }
        
        .copy-button:hover {
            background: #4F4CD5;
            transform: translateY(-2px);
        }
        
        .copy-button.copied {
            background: #10b981;
        }
        
        .hero-results {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin-bottom: 40px;
        }
        
        @media (max-width: 968px) {
            .hero-results {
                grid-template-columns: 1fr;
            }
        }
        
        .result-card {
            background: rgba(10,10,10,0.8);
            backdrop-filter: blur(10px);
            padding: 30px;
            border-radius: 16px;
            border: 1px solid #1C1C1E;
            position: relative;
            overflow: hidden;
            transition: transform 0.3s ease;
        }
        
        .result-card:hover {
            transform: translateY(-5px);
        }
        
        .result-card.winner {
            border-color: #5E5CE6;
            background: linear-gradient(180deg, rgba(94,92,230,0.1) 0%, rgba(10,10,10,0.9) 100%);
        }
        
        .result-card h3 {
            font-size: 1.5rem;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            gap: 10px;
            color: #ffffff;
        }
        
        .winner-badge {
            font-size: 0.8rem;
            padding: 4px 12px;
            border-radius: 20px;
            background: linear-gradient(135deg, #5E5CE6, #60a5fa);
            color: #ffffff;
            font-weight: 600;
        }
        
        .result-metric {
            display: flex;
            justify-content: space-between;
            padding: 12px 0;
            border-bottom: 1px solid rgba(28,28,30,0.5);
        }
        
        .result-metric:last-child {
            border-bottom: none;
        }
        
        .metric-label {
            color: #8E8E93;
        }
        
        .metric-value {
            font-weight: 600;
            font-size: 1.1rem;
            color: #ffffff;
        }
        
        .metric-value.highlight {
            background: linear-gradient(135deg, #5E5CE6 0%, #60a5fa 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            font-size: 1.3rem;
        }
        
        .section {
            background: rgba(10,10,10,0.8);
            backdrop-filter: blur(10px);
            padding: 40px;
            border-radius: 16px;
            margin-bottom: 30px;
            border: 1px solid #1C1C1E;
        }
        
        h2 {
            font-size: 2rem;
            margin-bottom: 25px;
            background: linear-gradient(135deg, #5E5CE6 0%, #60a5fa 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            font-weight: 600;
        }
        
        h3 {
            font-size: 1.3rem;
            margin: 30px 0 15px 0;
            color: #ffffff;
        }
        
        .chart-container {
            background: rgba(10,10,10,0.6);
            padding: 30px;
            border-radius: 16px;
            margin-bottom: 30px;
            border: 1px solid #1C1C1E;
        }
        
        .chart-wrapper {
            position: relative;
            height: 450px;
            margin: 20px 0;
        }
        
        .gap-analysis-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-top: 30px;
        }
        
        @media (max-width: 768px) {
            .gap-analysis-grid {
                grid-template-columns: 1fr;
            }
        }
        
        .gap-card {
            background: rgba(0,0,0,0.5);
            padding: 20px;
            border-radius: 12px;
            border: 1px solid #1C1C1E;
        }
        
        .gap-card h4 {
            font-size: 1.2rem;
            margin-bottom: 15px;
            color: #ffffff;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .badge-cutlass {
            width: 12px;
            height: 12px;
            background: #f59e0b;
            border-radius: 50%;
            box-shadow: 0 0 10px rgba(245,158,11,0.5);
        }
        
        .badge-trtllm {
            width: 12px;
            height: 12px;
            background: #ef4444;
            border-radius: 50%;
            box-shadow: 0 0 10px rgba(239,68,68,0.5);
        }
        
        .insights-section {
            background: linear-gradient(135deg, rgba(94,92,230,0.05) 0%, rgba(10,10,10,0.8) 100%);
            padding: 30px;
            border-radius: 16px;
            margin-top: 30px;
            border: 1px solid #1C1C1E;
        }
        
        .insights-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin-top: 20px;
        }
        
        @media (max-width: 768px) {
            .insights-grid {
                grid-template-columns: 1fr;
            }
        }
        
        .insight-card ul {
            list-style: none;
            padding: 0;
        }
        
        .insight-card li {
            padding: 8px 0;
            color: #cbd5e1;
            font-size: 0.95rem;
            position: relative;
            padding-left: 20px;
        }
        
        .insight-card li:before {
            content: "‚ñ∏";
            position: absolute;
            left: 0;
            color: #5E5CE6;
        }

        .insights-section {
                background: linear-gradient(135deg, rgba(94,92,230,0.08) 0%, rgba(10,10,10,0.95) 100%);
                padding: 40px;
                border-radius: 16px;
                margin-top: 40px;
                margin-bottom: 40px;
                border: 1px solid rgba(94,92,230,0.2);
                backdrop-filter: blur(10px);
            }
            
            .insights-section > h2 {
                font-size: 2rem;
                margin-bottom: 30px;
                background: linear-gradient(135deg, #5E5CE6 0%, #60a5fa 100%);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                font-weight: 600;
            }
            
            .insights-grid {
                display: grid;
                grid-template-columns: 1fr;
                gap: 30px;
                margin-top: 20px;
            }
            
            .insight-card {
                background: rgba(20,20,22,0.6);
                backdrop-filter: blur(10px);
                padding: 30px;
                border-radius: 12px;
                border: 1px solid rgba(94,92,230,0.15);
                transition: all 0.3s ease;
            }
            
            .insight-card:hover {
                border-color: rgba(94,92,230,0.4);
                background: rgba(20,20,22,0.8);
                box-shadow: 0 8px 32px rgba(94,92,230,0.1);
            }
            
            .insight-card > h3 {
                font-size: 1.5rem;
                color: #60a5fa;
                margin-bottom: 20px;
                font-weight: 600;
            }
            
            .conclusion-intro {
                background: rgba(94,92,230,0.05);
                padding: 16px 20px;
                border-left: 3px solid #5E5CE6;
                border-radius: 8px;
                margin-bottom: 25px;
            }
            
            .conclusion-intro p {
                color: #cbd5e1;
                font-size: 0.95rem;
                line-height: 1.6;
                margin: 0;
            }
            
            .conclusion-intro strong {
                color: #60a5fa;
                font-weight: 600;
            }
            
            .insight-section-group {
                margin-bottom: 28px;
            }
            
            .insight-section-group:last-child {
                margin-bottom: 0;
            }
            
            .insight-subsection-title {
                font-size: 1.1rem;
                color: #60a5fa;
                margin-bottom: 12px;
                font-weight: 600;
                display: flex;
                align-items: center;
                gap: 8px;
            }
            
            .insight-list {
                list-style: none;
                padding: 0;
                margin: 0;
                display: flex;
                flex-direction: column;
                gap: 10px;
            }
            
            .insight-list li {
                padding: 10px 0 10px 28px;
                color: #cbd5e1;
                font-size: 0.95rem;
                line-height: 1.6;
                position: relative;
            }
            
            .insight-list li::before {
                content: "‚ñ∏";
                position: absolute;
                left: 8px;
                color: #5E5CE6;
                font-weight: bold;
                font-size: 1.1rem;
            }
            
            .insight-list strong {
                color: #ffffff;
                font-weight: 600;
            }
            
            /* Responsive Design */
            @media (max-width: 768px) {
                .insights-section {
                    padding: 25px;
                    margin-top: 30px;
                    margin-bottom: 30px;
                }
                
                .insights-section > h2 {
                    font-size: 1.5rem;
                    margin-bottom: 20px;
                }
                
                .insight-card {
                    padding: 20px;
                }
                
                .insight-card > h3 {
                    font-size: 1.3rem;
                }
                
                .insight-subsection-title {
                    font-size: 1rem;
                }
                
                .insight-list li {
                    font-size: 0.9rem;
                    padding: 8px 0 8px 24px;
                }
            }

        .gpu-comparison-section {
            background: rgba(10,10,10,0.9);
            backdrop-filter: blur(10px);
            padding: 40px;
            border-radius: 16px;
            margin-bottom: 40px;
            border: 1px solid #1C1C1E;
        }
        
        .gpu-comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: rgba(0,0,0,0.5);
            border-radius: 12px;
            overflow: hidden;
        }
        
        .gpu-comparison-table th {
            background: linear-gradient(135deg, rgba(94,92,230,0.2) 0%, rgba(96,165,250,0.2) 100%);
            color: #60a5fa;
            font-weight: 600;
            text-align: left;
            padding: 15px;
            border-bottom: 2px solid rgba(94,92,230,0.3);
            font-size: 0.9rem;
            letter-spacing: 0.5px;
        }
        
        .gpu-comparison-table td {
            padding: 12px 15px;
            border-bottom: 1px solid rgba(28,28,30,0.5);
            font-size: 0.85rem;
            vertical-align: top;
        }

        .gpu-comparison-table tr:hover {
            background: rgba(94,92,230,0.05);
        }
        
        .metric-dimension {
            color: #8E8E93;
            font-weight: 600;
            white-space: nowrap;
        }
        
        .gpu-b200 {
            color: #10b981;
            font-weight: 600;
        }
        
        .gpu-h100 {
            color: #60a5fa;
            font-weight: 600;
        }
        
        .gpu-a100 {
            color: #f59e0b;
            font-weight: 600;
        }

        .highlight-value {
            color: #5E5CE6;
            font-weight: 700;
        }

        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: rgba(0,0,0,0.3);
            border-radius: 8px;
            overflow: hidden;
        }
        
        th, td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid rgba(28,28,30,0.5);
            font-size: 0.9rem;
        }
        
        th {
            background: rgba(94,92,230,0.1);
            color: #60a5fa;
            font-weight: 600;
            text-transform: uppercase;
            font-size: 0.85rem;
            letter-spacing: 0.5px;
        }
        
        tr:hover {
            background: rgba(94,92,230,0.05);
        }
        
        .perf-good {
            color: #10b981;
            font-weight: 600;
        }
        
        .perf-bad {
            color: #ef4444;
            font-weight: 600;
        }
        
        .perf-neutral {
            color: #f59e0b;
            font-weight: 600;
        }
        
        .custom-tooltip {
            position: absolute;
            background: rgba(30,41,59,0.95);
            backdrop-filter: blur(10px);
            border: 1px solid #475569;
            border-radius: 8px;
            padding: 12px;
            pointer-events: none;
            z-index: 1000;
            display: none;
            box-shadow: 0 10px 25px rgba(0,0,0,0.5);
        }
        
        .tooltip-title {
            font-weight: 600;
            color: #60a5fa;
            margin-bottom: 8px;
        }
        
        .tooltip-content {
            color: #e2e8f0;
            font-size: 0.9rem;
        }
        
        .tooltip-gap {
            margin-top: 8px;
            padding-top: 8px;
            border-top: 1px solid #475569;
        }
        
        .gap-positive {
            color: #ef4444;
        }
        
        .gap-negative {
            color: #10b981;
        }
        
        /* Theoretical Analysis Styles */
        .analysis-container {
            background: rgba(20, 20, 22, 0.6);
            border: 1px solid rgba(94, 92, 230, 0.2);
            border-radius: 16px;
            padding: 40px;
            margin: 40px 0;
            backdrop-filter: blur(10px);
        }
        .math-block {
            background: rgba(0, 0, 0, 0.3);
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
            border-left: 3px solid #5E5CE6;
            overflow-x: auto;
        }
        .regime-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-top: 30px;
        }
        .regime-card {
            background: rgba(255, 255, 255, 0.03);
            padding: 20px;
            border-radius: 12px;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }
        .callout-note {
            background: rgba(245, 158, 11, 0.1);
            border-left: 4px solid #f59e0b;
            padding: 20px;
            border-radius: 8px;
            margin-top: 30px;
        }
        .callout-title {
            color: #f59e0b;
            font-weight: 700;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        @media (max-width: 768px) {
            h1 { font-size: 2rem; }
            .section { padding: 20px; }
            table { font-size: 0.75rem; }
            th, td { padding: 8px; }
            .regime-grid { grid-template-columns: 1fr; }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>MoE at Scale on B200 GPUs: Expert Load Balance, and Backend Performance</h1>
        </header>

        <div class="gpu-comparison-section">
            <h2>GPU Architecture Comparison for MoE Inference</h2>
            <p style="color: #8E8E93; margin-bottom: 20px;">Hardware capabilities comparison across NVIDIA Blackwell, Hopper, and Ampere architectures</p>
            
            <table class="gpu-comparison-table">
                <thead>
                    <tr>
                        <th style="width: 20%;">Dimension (MoE-Related)</th>
                        <th style="width: 28%;">B200 (Blackwell)</th>
                        <th style="width: 26%;">H100 (Hopper)</th>
                        <th style="width: 26%;">A100 (Ampere)</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td class="metric-dimension">Tensor Core Gen & Precision</td>
                        <td class="gpu-b200"><strong>5th Gen</strong><br>FP4/FP6/FP8<br>2nd Gen Transformer Engine</td>
                        <td class="gpu-h100"><strong>4th Gen</strong><br>FP8 + Transformer Engine</td>
                        <td class="gpu-a100"><strong>3rd Gen</strong><br>TF32/BF16/FP16/INT8</td>
                    </tr>
                    <tr>
                        <td class="metric-dimension">Low Precision Performance<br>(Per Card)</td>
                        <td class="gpu-b200"><span class="highlight-value">FP8: 4.5/9 PFLOPS</span><br>(dense/sparse)<br>FP4: ~18 PFLOPS/card</td>
                        <td class="gpu-h100">FP8: ~2/4 PFLOPS<br>(dense/sparse)</td>
                        <td class="gpu-a100">BF16/FP16: 312/624 TFLOPS<br>(dense/sparse)</td>
                    </tr>
                    <tr>
                        <td class="metric-dimension">HBM Capacity & Bandwidth</td>
                        <td class="gpu-b200"><span class="highlight-value">180 GB HBM3e</span><br>~8 TB/s bandwidth</td>
                        <td class="gpu-h100">80 GB HBM3<br>>3 TB/s bandwidth</td>
                        <td class="gpu-a100">80 GB HBM2e<br>~2.0 TB/s bandwidth</td>
                    </tr>
                    <tr class="comm-highlight">
                        <td class="metric-dimension">üîó NVLink Bandwidth<br>(Direct GPU-GPU)</td>
                        <td class="gpu-b200"><span class="highlight-value">Gen5: 1.8 TB/s</span><br>(18√ó100 GB/s)</td>
                        <td class="gpu-h100">Gen4: 900 GB/s</td>
                        <td class="gpu-a100">Gen3: 600 GB/s</td>
                    </tr>
                    <tr>
                        <td class="metric-dimension">Hardware Decompression</td>
                        <td class="gpu-b200"><span class="highlight-value">‚úì DE Engine</span><br>~600 GB/s decompress<br>Snappy/LZ4/Deflate</td>
                        <td class="gpu-h100">‚úó Not available</td>
                        <td class="gpu-a100">‚úó Not available</td>
                    </tr>
                    <tr>
                        <td class="metric-dimension">New Instructions/Memory</td>
                        <td class="gpu-b200"><strong>tcgen05.mma</strong><br>Tensor Memory<br>Enhanced TMA broadcast</td>
                        <td class="gpu-h100">WGMMA + TMA<br>Thread block clusters</td>
                        <td class="gpu-a100">HMMA</td>
                    </tr>
                    <tr style="background: rgba(94,92,230,0.05);">
                        <td class="metric-dimension"><strong>MoE Impact Summary</strong></td>
                        <td class="significance">Lower precision + higher bandwidth enables efficient expert weight loading & GEMM fusion</td>
                        <td class="significance">Strong all-to-all performance with FP8 acceleration</td>
                        <td class="significance">Baseline MoE support, limited by bandwidth & communication</td>
                    </tr>
                </tbody>
            </table>
            
            <div style="margin-top: 20px; padding: 15px; background: rgba(94,92,230,0.1); border-radius: 8px; border-left: 4px solid #5E5CE6;">
                <p style="color: #cbd5e1; font-size: 0.9rem;">
                    <strong style="color: #60a5fa;">üîó Communication Metrics:</strong> The highlighted rows (NVLink bandwidth and NVSwitch domain) directly impact MoE's all-to-all communication patterns. 
                    B200's 3x improvement in NVLink bandwidth (1.8 TB/s vs 600 GB/s on A100) significantly reduces expert routing overhead in multi-GPU deployments.
                </p>
            </div>
        </div>

        <!-- Command Section -->
        <div class="command-section">
            <div class="section-header" onclick="toggleSection(this)">
                    <div class="toggle-icon">‚ñ∂</div>
                    <h2>‚öôÔ∏è Run High Throughput Benchmark Command</h2>
                </div>
                <div class="section-content">
                    <!-- Enable Round Robin Command -->
                    <div class="command-section" style="margin-top: 0; margin-bottom: 32px;">
                        <h2 style="color: #60a5fa;">Enable Round Robin</h2>
                        <div class="code-block">
                            <button class="copy-button" onclick="copyToClipboard(event)">üìã Copy</button>
                            <code>export ENABLE_PERFECT_ROUTER=1</code>
                        </div>
                        <p style="color: #8E8E93; margin-top: 10px;">Set this environment variable before running your MoE backend to enable perfect routing for benchmarking.</p>
                    </div>

                    <!-- Complete Benchmark Command -->
                    <div class="command-section" style="margin-top: 0; margin-bottom: 32px;">
                        <div class="section-header" onclick="toggleSection(this)" style="cursor: pointer;">
                            <div class="toggle-icon collapsed">‚ñ∂</div>
                            <h2 style="color: #60a5fa;">Complete Benchmark Script</h2>
                        </div>
                        <div class="section-content collapsed">
                            <div class="code-block">
                                <button class="copy-button" onclick="copyToClipboard(event)">üìã Copy</button>
                                <code>num_gpus=4
max_batch_size=640

cat &lt;&lt;EOF &gt; max_throughput.yaml
enable_attention_dp: true
cuda_graph_config:
    max_batch_size: ${max_batch_size}
    enable_padding: true
stream_interval: 10
moe_config:
    backend: CUTLASS
EOF

trtllm-bench \
    --model openai/gpt-oss-120b \
    throughput \
    --backend pytorch \
    --tp ${num_gpus} \
    --ep ${num_gpus} \
    --extra_llm_api_options max_throughput.yaml \
    --dataset gpt-oss-120b-1k2k.txt \
    --max_batch_size ${max_batch_size} \
    --concurrency $((max_batch_size * num_gpus)) \
    --num_requests $((max_batch_size * num_gpus * 3)) \
    --kv_cache_free_gpu_mem_fraction 0.9 \
    --streaming \
    --warmup 0 \
    --report_json max_throughput_benchmark.json</code>
                            </div>
                            <p style="color: #8E8E93; margin-top: 10px;">
                                Full benchmark command for running max throughput test on GPT-OSS-120B with 4 GPUs, using CUTLASS backend and Random Dataset (1k input/2k output).
                                Adjust <code style="background: rgba(96, 165, 250, 0.2); color: #60a5fa; padding: 2px 6px; border-radius: 4px;">num_gpus</code> for different configurations (2, 4, or 8).
                            </p>
                        </div>
                    </div>

                    <!-- Methodology Section -->
                    <div style="background: rgba(30, 30, 35, 0.8); border: 1px solid rgba(94, 92, 230, 0.3); border-radius: 12px; padding: 30px; margin-top: 30px; backdrop-filter: blur(10px);">
                        <h2 style="color: #60a5fa; margin-bottom: 20px; font-size: 1.5rem;">
                            üî¨ Methodology: Benchmarking with Round Robin Routing
                        </h2>
                        
                        <p style="color: #d1d5db; line-height: 1.8; margin-bottom: 20px;">
                            To rigorously isolate <strong>hardware throughput capability</strong> from <strong>model routing inefficiency</strong>, 
                            we <strong>leveraged the static Round Robin routing mechanism</strong> available in TRT-LLM's MoE implementation. 
                            This is not a theoretical calculation‚Äîit's a measurement of physical hardware limits under controlled experts load distribution.
                        </p>

                        <h3 style="color: #8b5cf6; margin-top: 25px; margin-bottom: 15px; font-size: 1.2rem;">
                            ‚öôÔ∏è Methodology Details
                        </h3>
                        
                        <div style="background: rgba(0, 0, 0, 0.4); border-left: 3px solid #60a5fa; padding: 20px; border-radius: 8px; margin-bottom: 20px;">
                            <p style="color: #d1d5db; line-height: 1.8; margin-bottom: 15px;">
                                By enabling <code style="background: rgba(96, 165, 250, 0.2); color: #60a5fa; padding: 2px 8px; border-radius: 4px;">ENABLE_PERFECT_ROUTER=1</code>, 
                                we bypass the model's learned gating choices and inject pre-calculated, perfectly balanced scores. 
                                This serves as a crucial <strong style="color: #10b981;">baseline control</strong> for measuring the impact of load imbalance:
                            </p>
                            
                            <ul style="color: #d1d5db; line-height: 2; padding-left: 25px; margin-bottom: 0; list-style-type: none;">
                                <li style="margin-bottom: 12px;">
                                    <strong style="color: #60a5fa;">‚Ä¢ Control Group (Round Robin):</strong> 
                                    Forces a deterministic, GPU-aware cyclic assignment. By cycling through EP GPUs in a fixed order, 
                                    this ensures near-perfect load distribution across <code style="background: rgba(96, 165, 250, 0.15); padding: 1px 6px; border-radius: 3px;">num_tokens √ó top_k</code> 
                                    total calls, with load difference <strong>at most ¬±1</strong> between any two GPUs.
                                </li>
                                <li style="margin-bottom: 12px;">
                                    <strong style="color: #60a5fa;">‚Ä¢ Experimental Group (Learned Router):</strong> 
                                    Runs the model's actual learned gating weights. Any performance drop compared to the Control Group can be 
                                    strictly attributed to <strong>algorithmic load imbalance</strong> rather than hardware limitations.
                                </li>
                                <li style="margin-bottom: 0;">
                                    <strong style="color: #60a5fa;">‚Ä¢ Full Hardware Stack:</strong> 
                                    Both configurations execute the complete MoE pipeline (Top-K ‚Üí Softmax ‚Üí All-to-All ‚Üí GEMM), 
                                    measuring <em>real physical latency</em> rather than theoretical estimates.
                                </li>
                            </ul>
                        </div>
                        
                        <!-- Mathematical Definition -->
                        <div style="background: rgba(255, 255, 255, 0.03); border: 1px solid rgba(139, 92, 246, 0.3); border-radius: 8px; padding: 20px; margin-bottom: 20px;">
                            <p style="color: #8b5cf6; font-weight: 600; margin-bottom: 12px; font-size: 1.05rem;">
                                Definition: Perfect Load Balance
                            </p>
                            <p style="color: #d1d5db; line-height: 1.7; margin-bottom: 12px;">
                                We formalize the ideal load distribution state as follows. For total tokens <em>T</em>, top-<em>k</em> routing, and <em>N</em> GPUs (EP size), the integer workload <em>L<sub>i</sub></em> (expert calls) on GPU <em>i</em> satisfies:
                            </p>
                            <div style="text-align: center; margin: 15px 0; padding: 15px; background: rgba(0, 0, 0, 0.3); border-radius: 6px;">
                                $$ \left| L_i - \frac{T \times k}{N} \right| < 1 \quad \forall i \in \{0, ..., N-1\} $$
                            </div>
                            <p style="color: #94a3b8; font-size: 0.9rem; line-height: 1.6; margin-bottom: 12px;">
                                This constraint represents the theoretical minimum variance for discrete task partitioning, ensuring no GPU waits for stragglers (T<sub>sync</sub> ‚Üí 0). 
                                Achieving this state effectively minimizes the <strong>auxiliary load balancing loss</strong> introduced in GShard [1] and corresponds to a <strong>capacity factor of 1.0</strong> with zero dropped tokens as described in Switch Transformer [2].
                            </p>
                            <div style="margin-top: 10px; padding-top: 10px; border-top: 1px solid rgba(139, 92, 246, 0.2); font-size: 0.8rem; color: #6b7280; line-height: 1.5;">
                                <strong style="color: #8b5cf6;">References:</strong><br>
                                [1] Lepikhin, D., et al. (2020). <em>"GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding."</em> ICLR 2021.<br>
                                [2] Fedus, W., et al. (2021). <em>"Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity."</em> JMLR 2022.
                            </div>
                        </div>

                        <h3 style="color: #8b5cf6; margin-top: 25px; margin-bottom: 15px; font-size: 1.2rem;">
                            üéØ Why This Matters
                        </h3>
                        
                        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px; margin-top: 15px;">
                            <div style="background: rgba(239, 68, 68, 0.1); border: 1px solid rgba(239, 68, 68, 0.3); border-radius: 8px; padding: 15px;">
                                <h4 style="color: #ef4444; margin-bottom: 10px; font-size: 1rem;">Real Router (Actual)</h4>
                                <p style="color: #d1d5db; font-size: 0.9rem; line-height: 1.6;">
                                    Tokens cluster into "hotspot" experts (e.g., Expert A gets 80% of tokens). 
                                    GPU 1 runs at high load while GPU 2 experiences significant idle time, creating the <strong>Straggler Effect</strong>.
                                </p>
                            </div>
                            
                            <div style="background: rgba(16, 185, 129, 0.1); border: 1px solid rgba(16, 185, 129, 0.3); border-radius: 8px; padding: 15px;">
                                <h4 style="color: #10b981; margin-bottom: 10px; font-size: 1rem;">Round Robin (Enforced)</h4>
                                <p style="color: #d1d5db; font-size: 0.9rem; line-height: 1.6;">
                                    Expert assignments are distributed <strong>as evenly as possible</strong> (¬±1 token difference). Token 1 ‚Üí Expert A, Token 2 ‚Üí Expert B... 
                                    GPUs achieve <strong>maximal effective utilization</strong> by eliminating routing skew.
                                </p>
                            </div>
                        </div>

                        <h3 style="color: #8b5cf6; margin-top: 25px; margin-bottom: 15px; font-size: 1.2rem;">
                            üí° Key Technical Properties
                        </h3>
                        
                        <ul style="color: #d1d5db; line-height: 2; padding-left: 25px;">
                            <li>
                                <strong style="color: #60a5fa;">GPU-Aware Routing:</strong> 
                                The Round Robin mechanism prioritizes <strong>inter-GPU</strong> load balance within the EP group, 
                                critical for minimizing the "straggler effect" and maximizing NVLink bandwidth utilization.
                            </li>
                            <li>
                                <strong style="color: #60a5fa;">Deterministic Assignment:</strong> 
                                Pre-computed indices ensure consistent routing patterns across runs, enabling reproducible benchmarking 
                                of hardware performance limits.
                            </li>
                            <li>
                                <strong style="color: #60a5fa;">Full Computation Graph:</strong> 
                                Unlike theoretical estimates, this approach executes the complete MoE pipeline including gating, routing, 
                                GEMM kernels, and All-to-All communication‚Äîmeasuring <em>actual hardware latency</em> under balanced conditions.
                            </li>
                        </ul>

                        <div style="background: rgba(245, 158, 11, 0.15); border-left: 4px solid #f59e0b; padding: 18px; border-radius: 8px; margin-top: 25px;">
                            <p style="color: #fbbf24; font-weight: 600; margin-bottom: 8px; font-size: 1.05rem;">
                                üìä Interpreting the Results
                            </p>
                            <p style="color: #d1d5db; line-height: 1.7; margin: 0;">
                                The performance gap between "Round Robin" (control) and "Learned Router" (real) configurations 
                                quantifies the <strong style="color: #fbbf24;">efficiency gap due to load imbalance</strong>. 
                                Across our benchmarks on GPT-OSS-120B (8 GPUs, CUTLASS), the learned routing strategy shows varying gap:
                                <strong style="color: #fbbf24;">18.3%</strong> on Random Dataset (19,355 vs 23,696 tok/s/gpu),
                                <strong style="color: #fbbf24;">7.5%</strong> on ShareGPT (22,051 vs 23,702 tok/s/gpu), and
                                <strong style="color: #fbbf24;">8.6%</strong> on openMath (29,757 vs 32,565 tok/s/gpu),
                                relative to the hardware's theoretical peak under perfect load distribution.
                            </p>
                        </div>
                    </div>
                </div>
        </div>

        <!-- MoE Architecture Diagram Section -->
        <div class="architecture-section" style="margin: 40px auto; max-width: 1200px; padding: 30px; background: rgba(10,10,10,0.8); border: 1px solid #1C1C1E; border-radius: 16px; backdrop-filter: blur(10px);">
            <h2 style="text-align: center; color: #60a5fa; margin-bottom: 30px; font-size: 2rem;">MoE Architecture</h2>
            <div class="architecture-diagram" style="display: flex; flex-direction: column; align-items: center;">
                <!-- <img src="./images/sparse_model_architecture.png" alt="Transformer block vs Transformer block with MoE" style="max-width: 1000px; width: 100%; height: auto; border-radius: 12px; box-shadow: 0 6px 30px rgba(0,0,0,0.5); margin: 0 auto; display: block; background: #ffffff; padding: 15px;"> -->
                <img src="./images/moe_communication.png" alt="Transformer block vs Transformer block with MoE" style="max-width: 1000px; width: 100%; height: auto; border-radius: 12px; box-shadow: 0 6px 30px rgba(0,0,0,0.5); margin: 0 auto; display: block; background: #ffffff; padding: 15px;">
                <p style="text-align: center; color: #8E8E93; margin-top: 20px; font-style: italic; font-size: 0.95rem; max-width: 900px;">
                    <strong>Figure 1:</strong> Evolution of MoE architectures and their communication patterns. 
                    (a) Basic MoE with local gating and weighted expert outputs. 
                    (b) Standard Transformer block with single FFN for reference. 
                    (c) MoE Transformer block replacing FFN with multiple experts (FFN_1 to FFN_E). 
                    (d) Advanced MoE with distributed experts requiring All-to-all communication between layers, showing increased complexity for multi-GPU scaling with experts FFN_1 to FFN_K and FFN_(K+1) to FFN_2K.
                </p>
            </div>
        </div>

        <!-- Dataset Tabs -->
        <div class="dataset-tabs">
            <button class="tab-button active" onclick="switchDataset('random')">
                Random Dataset(1k/2k)
            </button>
            <!-- <button class="tab-button" onclick="switchDataset('gsm8k')">
                GSM8K Dataset
            </button> -->
            <button class="tab-button" onclick="switchDataset('sharegpt')">
                OpenGVLab/ShareGPT-4o
            </button>
            <button class="tab-button" onclick="switchDataset('openmath')">
                nvidia/OpenMathInstruct-1
            </button>
        </div>

        <!-- GSM8K Dataset Content -->
        <!-- GSM8K Dataset Content -->
        <div id="gsm8k-content" class="dataset-content">
            <!-- Hero Results for GSM8K -->
            <div class="hero-results">
                <div class="result-card winner">
                    <h3>
                        üìä GSM8K Dataset
                        <span class="winner-badge">Variable Output</span>
                    </h3>
                    <div class="result-metric">
                        <span class="metric-label">Dataset Type</span>
                        <span class="metric-value">Math Reasoning (openai/gsm8k)</span>
                    </div>
                    <div class="result-metric">
                        <span class="metric-label">Output Variance</span>
                        <span class="metric-value highlight">High (Variable Sequence Length)</span>
                    </div>
                    <div class="result-metric">
                        <span class="metric-label">Number of Requests</span>
                        <span class="metric-value">From NVIDIA Benchmark</span>
                    </div>
                    <div class="result-metric">
                        <span class="metric-label">Tokenizer</span>
                        <span class="metric-value">openai/gpt-oss-120b</span>
                    </div>
                    <div class="result-metric">
                        <span class="metric-label">Best Config (4 GPU)</span>
                        <span class="metric-value">15,622 tok/s/gpu (CUTLASS)</span>
                    </div>
                </div>

                <div class="result-card">
                    <h3>
                        ‚ö° Scaling Efficiency
                        <span class="winner-badge">Throughput Performance</span>
                    </h3>
                    <div class="result-metric">
                        <span class="metric-label">Ideal</span>
                        <span class="metric-value">No experts load imbalance</span>
                    </div>
                    <div class="result-metric">
                        <span class="metric-label">EP=4 (CUTLASS)</span>
                        <span class="metric-value">-2.17% from Ideal</span>
                    </div>
                    <div class="result-metric">
                        <span class="metric-label">EP=4 (TRTLLM)</span>
                        <span class="metric-value">-3.08% from Ideal</span>
                    </div>
                    <div class="result-metric">
                        <span class="metric-label">EP=8 (CUTLASS)</span>
                        <span class="metric-value">-7.92% from Ideal</span>
                    </div>
                    <div class="result-metric">
                        <span class="metric-label">EP=8 (TRTLLM)</span>
                        <span class="metric-value">-10.86% from Ideal</span>
                    </div>
                </div>
            </div>

            <!-- GSM8K Charts -->
            <div class="section">
                <h2>GSM8K: MOE Load Balance Impact Analysis</h2>
                
                <div class="chart-container">
                    <h3>Throughput/GPU Scaling with GPU Count</h3>
                    <div class="chart-wrapper">
                        <canvas id="gsm8k-throughput-chart"></canvas>
                    </div>
                </div>

                <div class="chart-container">
                    <h3>Latency Scaling with GPU Count</h3>
                    <div class="chart-wrapper">
                        <canvas id="gsm8k-latency-chart"></canvas>
                    </div>
                </div>
                
                <!-- Performance Gap Analysis -->
                <div style="overflow-x: auto; margin-top: 30px;">
                    <h3>Throughput Performance (GSM8K Dataset)</h3>
                    <table>
                        <thead>
                            <tr>
                                <th>GPUs</th>
                                <th>EP Size</th>
                                <th>MoE Backend</th>
                                <th>Ideal Throughput(tokens/s/gpu)</th>
                                <th>Actual Throughput(tokens/s/gpu)</th>
                                <th>Throughput Gap</th>

                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>2</td>
                                <td>2</td>
                                <td>CUTLASS</td>
                                <td>14,437.10</td>
                                <td>14,216.19</td>
                                <td class="perf-neutral">-1.53%</td>
                            </tr>
                            <tr>
                                <td>2</td>
                                <td>2</td>
                                <td>TRTLLM</td>
                                <td>14,377.10</td>
                                <td>14,098.34</td>
                                <td class="perf-neutral">-1.94%</td>
                            </tr>
                            <tr class="highlight">
                                <td><strong>4</strong></td>
                                <td><strong>4</strong></td>
                                <td><strong>CUTLASS</strong></td>
                                <td><strong>15,968.47</strong></td>
                                <td><strong>15,622.13</strong></td>
                                <td class="perf-neutral"><strong>-2.17%</strong></td>
                            </tr>
                            <tr>
                                <td>4</td>
                                <td>4</td>
                                <td>TRTLLM</td>
                                <td>15,886.68</td>
                                <td>15,397.04</td>
                                <td class="perf-neutral">-3.08%</td>
                            </tr>
                            <tr>
                                <td>8</td>
                                <td>8</td>
                                <td>CUTLASS</td>
                                <td>11,553.53</td>
                                <td>10,699.03</td>
                                <td class="perf-bad">-7.92%</td>
                            </tr>
                            <tr>
                                <td>8</td>
                                <td>8</td>
                                <td>TRTLLM</td>
                                <td>9,666.57</td>
                                <td>8,616.56</td>
                                <td class="perf-bad">-10.86%</td>
                            </tr>
                        </tbody>
                    </table>
                    <h3>Total Latency Performance (GSM8K Dataset)</h3>
                    <table>
                        <thead>
                            <tr>
                                <th>GPUs</th> 
                                <th>EP Size</th>
                                <th>MoE Backend</th>
                                <th>Ideal Total Latency(s)</th>
                                <th>Actual Total Latency(s)</th>
                                <th>Latency Gap</th>
                                
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>2</td>
                                <td>2</td>
                                <td>CUTLASS</td>
                                <td>8.65</td>
                                <td>8.78</td>
                                <td class="perf-neutral">+1.55%</td>
                            </tr>
                            <tr>
                                <td>2</td>
                                <td>2</td>
                                <td>TRTLLM</td>
                                <td>8.69</td>
                                <td>8.86</td>
                                <td class="perf-neutral">+1.98%</td>
                            </tr>
                            <tr class="highlight">
                                <td><strong>4</strong></td>
                                <td><strong>4</strong></td>
                                <td><strong>CUTLASS</strong></td>
                                <td><strong>14.68</strong></td>
                                <td><strong>15.00</strong></td>
                                <td class="perf-neutral"><strong>+2.22%</strong></td>
                            </tr>
                            <tr>
                                <td>4</td>
                                <td>4</td>
                                <td>TRTLLM</td>
                                <td>14.75</td>
                                <td>15.22</td>
                                <td class="perf-neutral">+3.18%</td>
                            </tr>
                            <tr>
                                <td>8</td>
                                <td>8</td>
                                <td>CUTLASS</td>
                                <td>7.90</td>
                                <td>8.53</td>
                                <td class="perf-bad">+7.99%</td>
                            </tr>
                            <tr>
                                <td>8</td>
                                <td>8</td>
                                <td>TRTLLM</td>
                                <td>9.44</td>
                                <td>10.59</td>
                                <td class="perf-bad">+12.19%</td>
                            </tr>
                        </tbody>
                    </table>

                </div>
            </div>
        </div>

        <!-- ShareGPT Dataset Content -->
        <div id="sharegpt-content" class="dataset-content">
            <div class="section">
                <h2>ShareGPT: Multi-Model Performance Comparison</h2>
                
                <!-- Model Comparison Chart -->
                <div class="chart-container">
                    <h3>Throughput Comparison Across Models (8 GPUs)</h3>
                    <div class="chart-wrapper">
                        <canvas id="sharegpt-model-comparison-chart"></canvas>
                    </div>
                </div>

                <!-- Round Robin Impact Chart -->
                <div class="chart-container">
                    <h3>Round Robin Impact on Throughput</h3>
                    <div class="chart-wrapper">
                        <canvas id="sharegpt-perfect-router-chart"></canvas>
                    </div>
                </div>

                <!-- Model Comparison Table -->
                <div style="overflow-x: auto; margin-top: 30px;">
                    <h3>Model Performance Comparison (ShareGPT Dataset)</h3>
                    <table>
                        <thead>
                            <tr>
                                <th>Model</th>
                                <th>GPUs</th>
                                <th>MoE Backend</th>
                                <th>Router Type</th>
                                <th>Output Throughput (tok/s/gpu)</th>
                                <th>Quantization</th>
                            </tr>
                        </thead>
                        <tbody>
                            <!-- GPT-OSS-120B -->
                            <tr class="highlight">
                                <td><strong>GPT-OSS-120B</strong></td>
                                <td><strong>8</strong></td>
                                <td><strong>CUTLASS</strong></td>
                                <td><strong>Round Robin</strong></td>
                                <td class="perf-good"><strong>23,702</strong></td>
                                <td>W4A8_MXFP4_MXFP8</td>
                            </tr>
                            <tr>
                                <td>GPT-OSS-120B</td>
                                <td>8</td>
                                <td>CUTLASS</td>
                                <td>Default</td>
                                <td>22,051</td>
                                <td>W4A8_MXFP4_MXFP8</td>
                            </tr>
                            <tr>
                                <td>GPT-OSS-120B</td>
                                <td>8</td>
                                <td>TRT-LLM</td>
                                <td>Round Robin</td>
                                <td>17,739</td>
                                <td>W4A8_MXFP4_MXFP8</td>
                            </tr>
                            <tr>
                                <td>GPT-OSS-120B</td>
                                <td>8</td>
                                <td>TRT-LLM</td>
                                <td>Default</td>
                                <td>16,425</td>
                                <td>W4A8_MXFP4_MXFP8</td>
                            </tr>
                            <!-- DeepSeek-V3 -->
                            <tr class="highlight">
                                <td><strong>DeepSeek-V3</strong></td>
                                <td><strong>8</strong></td>
                                <td><strong>DeepGeMM</strong></td>
                                <td><strong>Round Robin</strong></td>
                                <td class="perf-good"><strong>3,061</strong></td>
                                <td>FP8_BLOCK_SCALES</td>
                            </tr>
                            <tr>
                                <td>DeepSeek-V3</td>
                                <td>8</td>
                                <td>DeepGeMM</td>
                                <td>Default</td>
                                <td>2,712</td>
                                <td>FP8_BLOCK_SCALES</td>
                            </tr>
                            <tr>
                                <td>DeepSeek-V3</td>
                                <td>7</td>
                                <td>DeepGeMM</td>
                                <td>Round Robin</td>
                                <td>3,409</td>
                                <td>FP8_BLOCK_SCALES</td>
                            </tr>
                            <tr>
                                <td>DeepSeek-V3</td>
                                <td>7</td>
                                <td>DeepGeMM</td>
                                <td>Default</td>
                                <td>3,178</td>
                                <td>FP8_BLOCK_SCALES</td>
                            </tr>
                            <!-- DeepSeek-R1 -->
                            <tr class="highlight">
                                <td><strong>DeepSeek-R1</strong></td>
                                <td><strong>8</strong></td>
                                <td><strong>DeepGeMM</strong></td>
                                <td><strong>Round Robin</strong></td>
                                <td class="perf-good"><strong>3,111</strong></td>
                                <td>FP8_BLOCK_SCALES</td>
                            </tr>
                            <tr>
                                <td>DeepSeek-R1</td>
                                <td>8</td>
                                <td>DeepGeMM</td>
                                <td>Default</td>
                                <td>2,854</td>
                                <td>FP8_BLOCK_SCALES</td>
                            </tr>
                            <!-- Qwen3-235B -->
                            <tr class="highlight">
                                <td><strong>Qwen3-235B-A22B</strong></td>
                                <td><strong>8</strong></td>
                                <td><strong>CUTLASS</strong></td>
                                <td><strong>Round Robin</strong></td>
                                <td class="perf-neutral"><strong>1,426</strong></td>
                                <td>NA</td>
                            </tr>
                            <tr>
                                <td>Qwen3-235B-A22B</td>
                                <td>8</td>
                                <td>CUTLASS</td>
                                <td>Default</td>
                                <td>1,358</td>
                                <td>NA</td>
                            </tr>
                        </tbody>
                    </table>

                    <div style="margin-top: 30px; padding: 20px; background: rgba(94,92,230,0.05); border-radius: 12px; border-left: 4px solid #5E5CE6;">
                        <h4 style="color: #60a5fa; margin-bottom: 15px; font-size: 1.1rem;">üí° Key Observations</h4>
                        <ul style="color: #cbd5e1; font-size: 0.9rem; line-height: 1.8; padding-left: 20px;">
                            <li><strong>GPT-OSS-120B dominates</strong> with 23,702 tok/s/gpu (Round Robin), achieving 7.7x throughput vs DeepSeek-V3</li>
                            <li><strong>DeepSeek models show consistency</strong>: DeepSeek-R1 and V3 achieve similar performance (~3,061-3,111 tok/s/gpu with Round Robin)</li>
                            <li><strong>Round Robin provides 5-13% boost</strong>: Most significant gains seen in DeepSeek-V3 (12.9% at 8 GPUs)</li>
                            <li><strong>GPU count matters</strong>: DeepSeek-V3 achieves higher per-GPU throughput with 7 GPUs (3,409) vs 8 GPUs (3,061), suggesting potential load balancing issues</li>
                            <li><strong>Quantization impact</strong>: W4A8 quantization (GPT-OSS) shows significantly better performance than FP8_BLOCK_SCALES (DeepSeek)</li>
                        </ul>
                    </div>
                </div>

                <h2 style="margin-top: 60px;">GPT-OSS-120B: Detailed Analysis</h2>
                
                <div class="chart-container">
                    <h3>Throughput/GPU Scaling (Higher is Better)</h3>
                    <div class="chart-wrapper">
                        <canvas id="sharegpt-throughput-chart"></canvas>
                    </div>
                </div>

                <!-- <div class="chart-container">
                    <h3>Total Latency Scaling (Lower is Better)</h3>
                    <div class="chart-wrapper">
                        <canvas id="sharegpt-latency-chart"></canvas>
                    </div>
                </div> -->
                
                <div style="overflow-x: auto; margin-top: 30px;">
                    <h3>Throughput Performance (GPT-OSS-120B on ShareGPT)</h3>
                    <table>
                        <thead>
                            <tr>
                                <th>GPUs</th>
                                <th>EP Size</th>
                                <th>MoE Backend</th>
                                <th>Ideal Throughput (tok/s/gpu)</th>
                                <th>Actual Throughput (tok/s/gpu)</th>
                                <th>Throughput Gap</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>1</td>
                                <td>1</td>
                                <td>CUTLASS</td>
                                <td>14,884</td>
                                <td>15,389</td>
                                <td class="perf-good">+3.39%</td>
                            </tr>
                            <tr>
                                <td>1</td>
                                <td>1</td>
                                <td>TRT-LLM</td>
                                <td>14,512</td>
                                <td>14,093</td>
                                <td class="perf-neutral">-2.89%</td>
                            </tr>
                            <tr>
                                <td>2</td>
                                <td>2</td>
                                <td>CUTLASS</td>
                                <td>19,686</td>
                                <td>18,783</td>
                                <td class="perf-neutral">-4.59%</td>
                            </tr>
                            <tr>
                                <td>2</td>
                                <td>2</td>
                                <td>TRT-LLM</td>
                                <td>18,507</td>
                                <td>17,595</td>
                                <td class="perf-neutral">-4.93%</td>
                            </tr>
                            <tr class="highlight">
                                <td><strong>4</strong></td>
                                <td><strong>4</strong></td>
                                <td><strong>CUTLASS</strong></td>
                                <td><strong>23,248</strong></td>
                                <td><strong>21,768</strong></td>
                                <td class="perf-neutral"><strong>-6.37%</strong></td>
                            </tr>
                            <tr>
                                <td>4</td>
                                <td>4</td>
                                <td>TRT-LLM</td>
                                <td>19,378</td>
                                <td>18,958</td>
                                <td class="perf-neutral">-2.17%</td>
                            </tr>
                            <tr>
                                <td>8</td>
                                <td>8</td>
                                <td>CUTLASS</td>
                                <td>23,702</td>
                                <td>22,051</td>
                                <td class="perf-bad">-6.96%</td>
                            </tr>
                            <tr>
                                <td>8</td>
                                <td>8</td>
                                <td>TRT-LLM</td>
                                <td>17,739</td>
                                <td>16,425</td>
                                <td class="perf-bad">-7.41%</td>
                            </tr>
                        </tbody>
                    </table>

                    <h3>Total Latency Performance (ShareGPT Dataset)</h3>
                    <table>
                        <thead>
                            <tr>
                                <th>GPUs</th>
                                <th>EP Size</th>
                                <th>MoE Backend</th>
                                <th>Ideal Total Latency (s)</th>
                                <th>Actual Total Latency (s)</th>
                                <th>Latency Gap</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>1</td>
                                <td>1</td>
                                <td>CUTLASS</td>
                                <td>264.18</td>
                                <td>255.52</td>
                                <td class="perf-good">-3.28%</td>
                            </tr>
                            <tr>
                                <td>1</td>
                                <td>1</td>
                                <td>TRT-LLM</td>
                                <td>270.97</td>
                                <td>279.01</td>
                                <td class="perf-neutral">+2.97%</td>
                            </tr>
                            <tr>
                                <td>2</td>
                                <td>2</td>
                                <td>CUTLASS</td>
                                <td>199.74</td>
                                <td>209.35</td>
                                <td class="perf-neutral">+4.81%</td>
                            </tr>
                            <tr>
                                <td>2</td>
                                <td>2</td>
                                <td>TRT-LLM</td>
                                <td>212.47</td>
                                <td>223.48</td>
                                <td class="perf-neutral">+5.18%</td>
                            </tr>
                            <tr class="highlight">
                                <td><strong>4</strong></td>
                                <td><strong>4</strong></td>
                                <td><strong>CUTLASS</strong></td>
                                <td><strong>169.14</strong></td>
                                <td><strong>180.64</strong></td>
                                <td class="perf-neutral"><strong>+6.80%</strong></td>
                            </tr>
                            <tr>
                                <td>4</td>
                                <td>4</td>
                                <td>TRT-LLM</td>
                                <td>202.92</td>
                                <td>207.42</td>
                                <td class="perf-neutral">+2.22%</td>
                            </tr>
                            <tr>
                                <td>8</td>
                                <td>8</td>
                                <td>CUTLASS</td>
                                <td>165.90</td>
                                <td>178.32</td>
                                <td class="perf-bad">+7.48%</td>
                            </tr>
                            <tr>
                                <td>8</td>
                                <td>8</td>
                                <td>TRT-LLM</td>
                                <td>221.66</td>
                                <td>239.40</td>
                                <td class="perf-bad">+8.01%</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
        </div>

        <!-- Random Dataset Content -->
    <div id="random-content" class="dataset-content active">
            <!-- Hero Results for Random Dataset -->
            <!-- <div class="hero-results">
                <div class="result-card">
                    <h3>üìä Random Dataset</h3>

                    <div class="result-metric">
                    <span class="metric-label">Input Tokens</span>
                    <span class="metric-value">1024 (fixed)</span>
                    </div>
                    <div class="result-metric">
                    <span class="metric-label">Output Tokens</span>
                    <span class="metric-value">2048 (fixed)</span>
                    </div>
                    <div class="result-metric">
                    <span class="metric-label">Requests</span>
                    <span class="metric-value">20,000</span>
                    </div>
                    <div class="result-metric">
                    <span class="metric-label">Tokenizer</span>
                    <span class="metric-value">openai/gpt-oss-120b</span>
                    </div>
                </div>
            </div> -->


            <!-- Random Dataset Charts -->
            <div class="section">
                <h2>Random Dataset: Scaling & Load Balance Analysis</h2>
                
                <div class="chart-container">
                    <h3>Throughput/GPU Scaling with GPU Count</h3>
                    <div class="chart-wrapper">
                        <canvas id="random-scaling-chart"></canvas>
                    </div>
                </div>

                <!-- <div class="chart-container">
                    <h3>Latency Scaling with GPU Count</h3>
                    <div class="chart-wrapper">
                        <canvas id="random-latency-scaling-chart"></canvas>
                    </div>
                </div> -->

                <!-- Theoretical Analysis Section -->
                <div class="analysis-container">
                    <h2 style="color: #60a5fa; margin-bottom: 20px; display: flex; align-items: center; gap: 10px;">
                        Theoretical Analysis: The Physics of Linear Scaling
                    </h2>
                    
                    <p style="color: #cbd5e1; margin-bottom: 25px; font-size: 1.05rem; line-height: 1.7;">
                        Our benchmark reveals a counter-intuitive phenomenon: <strong>Per-GPU throughput rises linearly</strong> from 1 to 4 GPUs, implying a super-linear total speedup. However, this trend abruptly reverses at 8 GPUs. This behavior marks the transition between two distinct physical regimes: the <strong>Memory-Bound Regime</strong> and the <strong>Latency-Bound Regime</strong>.
                    </p>

                    <div class="math-block" style="border-left-color: #60a5fa;">
                        <p style="color: #e2e8f0; margin-bottom: 10px; font-weight: 600;">1. The Throughput-Latency Inverse Relationship</p>
                        <p style="color: #94a3b8; font-size: 0.9rem; margin-bottom: 10px;">
                            In a weak scaling setup (fixed batch size \(B\) per GPU), the Per-GPU Throughput \(Q(N)\) is strictly governed by the end-to-end step latency \(T(N)\):
                        </p>
                        $$ Q_{\text{gpu}}(N) = \frac{\text{Batch}_{\text{gpu}}}{T(N)} \propto \frac{1}{T(N)} $$
                        
                        <p style="color: #e2e8f0; margin-top: 20px; margin-bottom: 10px; font-weight: 600;">2. Latency Decomposition (Amdahl's Law Extended)</p>
                        <p style="color: #94a3b8; font-size: 0.9rem;">
                            The single-step latency \(T(N)\) consists of the parallelizable computation/memory access and the serialization overhead (communication):
                        </p>
                        $$ T(N) \approx \underbrace{\frac{T_{\text{mem}}(1)}{N}}_{\text{Gain: Memory Aggregation}} + \underbrace{T_{\text{overhead}}}_{\text{Fixed: Kernel Launch}} + \underbrace{T_{\text{comm}}(N)}_{\text{Loss: All-to-All}} $$
                    </div>

                    <div class="regime-grid">
                        <div class="regime-card" style="border: 1px solid rgba(16, 185, 129, 0.3); background: linear-gradient(180deg, rgba(16, 185, 129, 0.05) 0%, rgba(0,0,0,0) 100%);">
                            <h4 style="color: #10b981; margin-bottom: 15px; font-size: 1.1rem;">Phase I: The Memory Wall Breakout<br><span style="font-size: 0.85rem; opacity: 0.8;">(1 ‚Üí 4 GPUs)</span></h4>
                            <ul style="padding-left: 20px; color: #cbd5e1; font-size: 0.9rem; line-height: 1.6;">
                                <li style="margin-bottom: 8px;"><strong>Mechanism:</strong> GPT-OSS-120B is too large for a single GPU's HBM bandwidth. Inference is stall-bound waiting for weights.</li>
                                <li style="margin-bottom: 8px;"><strong>Scaling:</strong> As \(N\) increases, we aggregate HBM bandwidth. The memory term \(\frac{T_{mem}}{N}\) dominates the equation.</li>
                                <li style="margin-bottom: 8px;"><strong>Result:</strong> Latency drops linearly (\(T \downarrow\)), causing Throughput to rise linearly (\(Q \uparrow\)).</li>
                            </ul>
                        </div>

                        <div class="regime-card" style="border: 1px solid rgba(239, 68, 68, 0.3); background: linear-gradient(180deg, rgba(239, 68, 68, 0.05) 0%, rgba(0,0,0,0) 100%);">
                            <h4 style="color: #ef4444; margin-bottom: 15px; font-size: 1.1rem;">Phase II: The Communication Wall<br><span style="font-size: 0.85rem; opacity: 0.8;">(N = 8 GPUs)</span></h4>
                            <ul style="padding-left: 20px; color: #cbd5e1; font-size: 0.9rem; line-height: 1.6;">
                                <li style="margin-bottom: 8px;"><strong>The Inflection Point:</strong> At 8 GPUs, the memory access time is already minimal (diminishing returns).</li>
                                <li style="margin-bottom: 8px;"><strong>Small Message Penalty:</strong> MoE EP requires All-to-All. As \(N\) grows, the message size per peer (\(Batch/N\)) shrinks. NVLink bandwidth utilization drops for small messages, making the system <strong>Latency-Bound</strong>.</li>
                                <li style="margin-bottom: 8px;"><strong>Result:</strong> \(T_{comm}\) rises faster than \(T_{mem}\) falls. Total Latency increases, Throughput drops.</li>
                            </ul>
                        </div>
                    </div>

                    <div style="margin-top: 30px; background: rgba(0,0,0,0.4); padding: 20px; border-radius: 8px; border: 1px dashed #5E5CE6;">
                        <h4 style="color: #cbd5e1; font-size: 0.95rem; margin-bottom: 10px;">ÔøΩ The Drop Condition (Mathematical Criterion)</h4>
                        <p style="color: #94a3b8; font-size: 0.9rem; margin-bottom: 10px;">
                            Performance degrades when the cost of coordination exceeds the benefit of parallelization:
                        </p>
                        <div style="font-family: 'Monaco', monospace; color: #e2e8f0; text-align: center; background: rgba(255,255,255,0.05); padding: 10px; border-radius: 6px;">
                            $$ |\Delta T_{\text{comm\_overhead}}| > |\Delta T_{\text{compute\_gain}}| $$
                        </div>
                        <p style="color: #94a3b8; font-size: 0.9rem; margin-top: 10px;">
                            This typically occurs when the kernel execution time drops below the <strong>Kernel Launch Latency (~3-5Œºs)</strong> or when interconnect latency dominates due to fragmented packets.
                        </p>
                    </div>

                    <div class="callout-note">
                        <div class="callout-title">‚ö†Ô∏è Note: Decode vs. Prefill Dynamics</div>
                        <p style="color: #cbd5e1; font-size: 0.95rem; line-height: 1.6;">
                            This analysis focuses on the <strong>Decode Phase (Generation)</strong>, which dominates our 2k-output workload (>99% of runtime). Decode is inherently memory/latency-bound.
                        </p>
                        <p style="color: #cbd5e1; font-size: 0.95rem; line-height: 1.6; margin-top: 8px;">
                            <strong>Prefill (TTFT)</strong> is typically compute-bound. In scenarios with short output lengths (e.g., RAG), the scaling curve would look flatter, as the "Memory Wall Breakout" effect is less pronounced during the compute-heavy prefill phase.
                        </p>
                    </div>
                </div>
                
                <!-- Detailed Performance Table -->
                <div style="overflow-x: auto; margin-top: 30px;">
                    <h3>Throughput Performance (Random Dataset)</h3>
                    <table>
                        <thead>
                            <tr>
                                <th>GPUs</th>
                                <th>EP Size</th>
                                <th>MoE Backend</th>
                                <th>Ideal Throughput(tokens/s/gpu)</th>
                                <th>Actual Throughput(tokens/s/gpu)</th>
                                <th>Throughput Gap</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>1</td>
                                <td>1</td>
                                <td>CUTLASS</td>
                                <td>14,902</td>
                                <td>15,795</td>
                                <td class="perf-good">+6.0%</td>
                            </tr>
                            <tr>
                                <td>1</td>
                                <td>1</td>
                                <td>TRTLLM</td>
                                <td>14,530</td>
                                <td>14,256</td>
                                <td class="perf-neutral">-1.9%</td>
                            </tr>
                            <tr>
                                <td>2</td>
                                <td>2</td>
                                <td>CUTLASS</td>
                                <td>19,702</td>
                                <td>18,550</td>
                                <td class="perf-neutral">-5.8%</td>
                            </tr>
                            <tr>
                                <td>2</td>
                                <td>2</td>
                                <td>TRTLLM</td>
                                <td>18,582</td>
                                <td>17,161</td>
                                <td class="perf-neutral">-7.6%</td>
                            </tr>
                            <tr class="highlight">
                                <td><strong>4</strong></td>
                                <td><strong>4</strong></td>
                                <td><strong>CUTLASS</strong></td>
                                <td><strong>23,277</strong></td>
                                <td><strong>20,859</strong></td>
                                <td class="perf-bad"><strong>-10.4%</strong></td>
                            </tr>
                            <tr>
                                <td>4</td>
                                <td>4</td>
                                <td>TRTLLM</td>
                                <td>19,639</td>
                                <td>18,051</td>
                                <td class="perf-bad">-8.1%</td>
                            </tr>
                            <tr>
                                <td>8</td>
                                <td>8</td>
                                <td>CUTLASS</td>
                                <td>23,696</td>
                                <td>19,355</td>
                                <td class="perf-bad">-18.3%</td>
                            </tr>
                            <tr>
                                <td>8</td>
                                <td>8</td>
                                <td>TRTLLM</td>
                                <td>17,665</td>
                                <td>14,678</td>
                                <td class="perf-bad">-16.9%</td>
                            </tr>
                        </tbody>
                    </table>
                    <h3>Total Latency Performance (Random Dataset)</h3>
                    <table>
                        <thead>
                            <tr>
                                <th>GPUs</th>   
                                <th>EP Size</th>
                                <th>MoE Backend</th>
                                <th>Ideal Total Latency(s)</th>
                                <th>Actual Total Latency(s)</th>
                                <th>Latency Gap</th>
                                
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>1</td>
                                <td>1</td>
                                <td>CUTLASS</td>
                                <td>263.854</td>
                                <td>248.956</td>
                                <td class="perf-good">-5.6%</td>
                            </tr>
                            <tr>
                                <td>1</td>
                                <td>1</td>
                                <td>TRTLLM</td>
                                <td>270.607</td>
                                <td>275.824</td>
                                <td class="perf-neutral">+1.9%</td>
                            </tr>
                            <tr>
                                <td>2</td>
                                <td>2</td>
                                <td>CUTLASS</td>
                                <td>199.580</td>
                                <td>211.977</td>
                                <td class="perf-neutral">+6.2%</td>
                            </tr>
                            <tr>
                                <td>2</td>
                                <td>2</td>
                                <td>TRTLLM</td>
                                <td>211.616</td>
                                <td>229.135</td>
                                <td class="perf-neutral">+8.3%</td>
                            </tr>
                            <tr class="highlight">
                                <td><strong>4</strong></td>
                                <td><strong>4</strong></td>
                                <td><strong>CUTLASS</strong></td>
                                <td><strong>168.929</strong></td>
                                <td><strong>188.509</strong></td>
                                <td class="perf-bad"><strong>+11.6%</strong></td>
                            </tr>
                            <tr>
                                <td>4</td>
                                <td>4</td>
                                <td>TRTLLM</td>
                                <td>200.225</td>
                                <td>217.835</td>
                                <td class="perf-bad">+8.8%</td>
                            </tr>
                            <tr>
                                <td>8</td>
                                <td>8</td>
                                <td>CUTLASS</td>
                                <td>168.929</td>
                                <td>188.509</td>
                                <td class="perf-bad">+11.6%</td>
                            </tr>
                            <tr>
                                <td>8</td>
                                <td>8</td>
                                <td>TRTLLM</td>
                                <td>200.225</td>
                                <td>217.835</td>
                                <td class="perf-bad">+8.8%</td>
                            </tr>
                        </tbody>
                    </table>
                    <!-- Expert Parallelism Charts -->
                    <div style="margin-top: 60px; margin-bottom: 60px;">
                        <h2 style="text-align: center; font-size: 2rem; margin-bottom: 40px; background: linear-gradient(135deg, #5E5CE6 0%, #60a5fa 100%); -webkit-background-clip: text; -webkit-text-fill-color: transparent; background-clip: text;">Expert Parallelism Analysis</h2>
                        
                        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 30px; margin-bottom: 40px;">
                            <!-- Throughput Chart -->
                            <div style="background: rgba(28, 28, 30, 0.8); border: 1px solid #2C2C2E; border-radius: 16px; padding: 30px; backdrop-filter: blur(10px);">
                                <h3 style="font-size: 1.3rem; margin-bottom: 20px; color: #60a5fa;">Throughput Impact (tok/s)</h3>
                                <div style="position: relative; height: 350px;">
                                    <canvas id="ep-throughput-chart"></canvas>
                                </div>
                                <p style="font-size: 0.9rem; color: #8E8E93; margin-top: 15px; padding-top: 15px; border-top: 1px solid #2C2C2E;">
                                    Comparison of output throughput per GPU across CUTLASS and TRT-LLM backends with Open and Closed Expert Parallelism configurations.
                                </p>
                            </div>
                            
                            <!-- Latency Chart -->
                            <div style="background: rgba(28, 28, 30, 0.8); border: 1px solid #2C2C2E; border-radius: 16px; padding: 30px; backdrop-filter: blur(10px);">
                                <h3 style="font-size: 1.3rem; margin-bottom: 20px; color: #60a5fa;">Latency Impact (ms)</h3>
                                <div style="position: relative; height: 350px;">
                                    <canvas id="ep-latency-chart"></canvas>
                                </div>
                                <p style="font-size: 0.9rem; color: #8E8E93; margin-top: 15px; padding-top: 15px; border-top: 1px solid #2C2C2E;">
                                    Total latency comparison across different GPU configurations and Expert Parallelism sizes. Lower values indicate better performance.
                                </p>
                            </div>
                        </div>
                    </div>
                    <!-- Benchmark Results Table -->
                     <div style="margin-top: 40px;">
                        <h3>Expert Parallelism: Throughput Impact Across MoE Backends</h3>
                        <table>
                            <thead>
                                <tr>
                                    <th>MoE Backend</th>
                                    <th>GPUs</th>
                                    <th>EP Size</th>
                                    <th>Output Throughput/GPU (tok/s)</th>
                                    <th>Throughput Gap (%)</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr><td><strong>CUTLASS (Open EP)</strong></td><td><strong>8</strong></td><td><strong>8</strong></td><td><strong>19355.29</strong></td><td class="perf-good"><strong>+30.5%</strong></td></tr>
                                <tr><td>CUTLASS (Closed EP)</td><td>8</td><td>1</td><td>14834.88</td><td class="perf-good">0%</td></tr>
                                <tr><td><strong>CUTLASS (Open EP)</strong></td><td><strong>4</strong></td><td><strong>4</strong></td><td><strong>20859.29</strong></td><td class="perf-neutral"><strong>+11.1%</strong></td></tr>
                                <tr><td>CUTLASS (Closed EP)</td><td>4</td><td>1</td><td>18785.89</td><td class="perf-neutral">0%</td></tr>
                                <tr><td><strong>CUTLASS (Open EP)</strong></td><td><strong>2</strong></td><td><strong>2</strong></td><td><strong>18549.97</strong></td><td class="perf-neutral"><strong>+7.5%</strong></td></tr>
                                <tr><td>CUTLASS (Closed EP)</td><td>2</td><td>1</td><td>17249.07</td><td class="perf-neutral">0%</td></tr>
                                <tr><td><strong>TRTLLM (Open EP)</strong></td><td><strong>8</strong></td><td><strong>8</strong></td><td><strong>14677.82</strong></td><td class="perf-bad"><strong>-13.4%</strong></td></tr>
                                <tr><td>TRTLLM (Closed EP)</td><td>8</td><td>1</td><td>16954.52</td><td class="perf-bad">0%</td></tr>
                                <tr><td><strong>TRTLLM (Open EP)</strong></td><td><strong>4</strong></td><td><strong>4</strong></td><td><strong>18051.06</strong></td><td class="perf-bad"><strong>-12.3%</strong></td></tr>
                                <tr><td>TRTLLM (Closed EP)</td><td>4</td><td>1</td><td>20584.83</td><td class="perf-bad">0%</td></tr>
                                <tr><td><strong>TRTLLM (Open EP)</strong></td><td><strong>2</strong></td><td><strong>2</strong></td><td><strong>17160.87</strong></td><td class="perf-bad"><strong>-4.5%</strong></td></tr>
                                <tr><td>TRTLLM (Closed EP)</td><td>2</td><td>1</td><td>17969.66</td><td class="perf-bad">0%</td></tr>
                            </tbody>
                        </table>
                    </div>
                    <div style="margin-top: 40px;">
                        <h3>Expert Parallelism: Latency Impact Across MoE Backends</h3>
                        <table>
                            <thead>
                                <tr>
                                    <th>MoE Backend</th>
                                    <th>GPUs</th>
                                    <th>EP Size</th>
                                    <th>Total Latency (ms)</th>
                                    <th>Latency Gap (%)</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr><td><strong>CUTLASS (Open EP)</strong></td><td><strong>8</strong></td><td><strong>8</strong></td><td><strong>203156.85</strong></td><td class="perf-good"><strong>-23.3%</strong></td></tr>
                                <tr><td>CUTLASS (Closed EP)</td><td>8</td><td>1</td><td>265061.79</td><td class="perf-good">0%</td></tr>
                                <tr><td><strong>CUTLASS (Open EP)</strong></td><td><strong>4</strong></td><td><strong>4</strong></td><td><strong>188508.83</strong></td><td class="perf-neutral"><strong>-9.9%</strong></td></tr>
                                <tr><td>CUTLASS (Closed EP)</td><td>4</td><td>1</td><td>209314.52</td><td class="perf-neutral">0%</td></tr>
                                <tr><td><strong>CUTLASS (Open EP)</strong></td><td><strong>2</strong></td><td><strong>2</strong></td><td><strong>211976.65</strong></td><td class="perf-neutral"><strong>-7.0%</strong></td></tr>
                                <tr><td>CUTLASS (Closed EP)</td><td>2</td><td>1</td><td>227963.58</td><td class="perf-neutral">0%</td></tr>
                                <tr><td><strong>TRTLLM (Open EP)</strong></td><td><strong>8</strong></td><td><strong>8</strong></td><td><strong>267898.03</strong></td><td class="perf-bad"><strong>+15.5%</strong></td></tr>
                                <tr><td>TRTLLM (Closed EP)</td><td>8</td><td>1</td><td>231924.01</td><td class="perf-bad">0%</td></tr>
                                <tr><td><strong>TRTLLM (Open EP)</strong></td><td><strong>4</strong></td><td><strong>4</strong></td><td><strong>217835.41</strong></td><td class="perf-bad"><strong>+14.0%</strong></td></tr>
                                <tr><td>TRTLLM (Closed EP)</td><td>4</td><td>1</td><td>191022.23</td><td class="perf-bad">0%</td></tr>
                                <tr><td><strong>TRTLLM (Open EP)</strong></td><td><strong>2</strong></td><td><strong>2</strong></td><td><strong>229135.21</strong></td><td class="perf-bad"><strong>+4.7%</strong></td></tr>
                                <tr><td>TRTLLM (Closed EP)</td><td>2</td><td>1</td><td>218822.20</td><td class="perf-bad">0%</td></tr>
                            </tbody>
                        </table>
                    </div>

                    <!-- Multi-Model 8 GPU Comparison Section -->
                    <div style="margin-top: 60px; border: 1px solid #5E5CE6; background: rgba(94,92,230,0.05); padding: 40px; border-radius: 16px;">
                        <h2 style="display: flex; align-items: center; gap: 10px; margin-bottom: 10px;">
                            üöÄ 8 GPUs Multi-Model Benchmark Comparison
                            <span style="font-size: 0.8rem; background: #5E5CE6; color: white; padding: 4px 12px; border-radius: 20px; -webkit-text-fill-color: white;">Random Dataset (1k/2k)</span>
                        </h2>
                        <p style="color: #cbd5e1; margin-bottom: 30px; font-size: 0.95rem;">
                            Cross-model comparison of <strong>GPT-OSS-120B</strong>, <strong>Qwen3-235B-A22B</strong>, <strong>DeepSeek-V3</strong>, and <strong>DeepSeek-R1</strong> on 8x B200 GPUs (TP=8, EP=8).
                        </p>

                        <div class="chart-container">
                            <h3>Throughput per GPU (8 GPUs) - Cross Model Comparison</h3>
                            <div class="chart-wrapper">
                                <canvas id="random-8gpu-comparison-chart"></canvas>
                            </div>
                        </div>

                        <div class="chart-container">
                            <h3>Round Robin Impact on Throughput</h3>
                            <div class="chart-wrapper">
                                <canvas id="random-8gpu-perfect-router-chart"></canvas>
                            </div>
                        </div>

                        <div style="overflow-x: auto; margin-top: 30px;">
                            <h3>Detailed Performance Data (8 GPUs, TP=8, EP=8)</h3>
                            <table>
                                <thead>
                                    <tr>
                                        <th>Model</th>
                                        <th>Backend</th>
                                        <th>Router</th>
                                        <th>Throughput (tok/s/gpu)</th>
                                        <th>Total Latency (ms)</th>
                                        <th>Quantization</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr class="highlight" style="background: rgba(16, 185, 129, 0.15);">
                                        <td><strong>GPT-OSS-120B</strong></td>
                                        <td><strong>CUTLASS</strong></td>
                                        <td><strong>Default</strong></td>
                                        <td class="perf-good"><strong>19,355</strong></td>
                                        <td>203,157</td>
                                        <td>W4A8_MXFP4_MXFP8</td>
                                    </tr>
                                    <tr>
                                        <td>GPT-OSS-120B</td>
                                        <td>CUTLASS</td>
                                        <td>Round Robin</td>
                                        <td class="perf-good">23,696</td>
                                        <td>165,942</td>
                                        <td>W4A8_MXFP4_MXFP8</td>
                                    </tr>
                                    <tr>
                                        <td>GPT-OSS-120B</td>
                                        <td>TRT-LLM</td>
                                        <td>Default</td>
                                        <td>14,678</td>
                                        <td>267,898</td>
                                        <td>W4A8_MXFP4_MXFP8</td>
                                    </tr>
                                    <tr>
                                        <td>GPT-OSS-120B</td>
                                        <td>TRT-LLM</td>
                                        <td>Round Robin</td>
                                        <td>17,665</td>
                                        <td>222,592</td>
                                        <td>W4A8_MXFP4_MXFP8</td>
                                    </tr>
                                    <tr class="highlight" style="background: rgba(245, 158, 11, 0.15);">
                                        <td><strong>Qwen3-235B-A22B</strong></td>
                                        <td><strong>CUTLASS</strong></td>
                                        <td><strong>Default</strong></td>
                                        <td class="perf-neutral"><strong>2,897</strong></td>
                                        <td>1,357,350</td>
                                        <td>NA</td>
                                    </tr>
                                    <tr>
                                        <td>Qwen3-235B-A22B</td>
                                        <td>CUTLASS</td>
                                        <td>Round Robin</td>
                                        <td class="perf-neutral">3,219</td>
                                        <td>1,221,393</td>
                                        <td>NA</td>
                                    </tr>
                                    <tr>
                                        <td>Qwen3-235B-A22B</td>
                                        <td>TRT-LLM</td>
                                        <td>Default</td>
                                        <td>2,851</td>
                                        <td>1,379,004</td>
                                        <td>NA</td>
                                    </tr>
                                    <tr>
                                        <td>Qwen3-235B-A22B</td>
                                        <td>TRT-LLM</td>
                                        <td>Round Robin</td>
                                        <td>3,188</td>
                                        <td>1,233,305</td>
                                        <td>NA</td>
                                    </tr>
                                    <tr class="highlight" style="background: rgba(239, 68, 68, 0.15);">
                                        <td><strong>DeepSeek-V3</strong></td>
                                        <td><strong>DeepGeMM</strong></td>
                                        <td><strong>Default</strong></td>
                                        <td class="perf-neutral"><strong>2,598</strong></td>
                                        <td>1,513,529</td>
                                        <td>FP8_BLOCK_SCALES</td>
                                    </tr>
                                    <tr>
                                        <td>DeepSeek-V3</td>
                                        <td>DeepGeMM</td>
                                        <td>Round Robin</td>
                                        <td class="perf-neutral">3,081</td>
                                        <td>1,276,345</td>
                                        <td>FP8_BLOCK_SCALES</td>
                                    </tr>
                                    <tr class="highlight" style="background: rgba(168, 85, 247, 0.15);">
                                        <td><strong>DeepSeek-R1</strong></td>
                                        <td><strong>DeepGeMM</strong></td>
                                        <td><strong>Default</strong></td>
                                        <td class="perf-neutral"><strong>2,586</strong></td>
                                        <td>1,520,385</td>
                                        <td>FP8_BLOCK_SCALES</td>
                                    </tr>
                                    <tr>
                                        <td>DeepSeek-R1</td>
                                        <td>DeepGeMM</td>
                                        <td>Round Robin</td>
                                        <td class="perf-neutral">3,107</td>
                                        <td>1,265,684</td>
                                        <td>FP8_BLOCK_SCALES</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>

                        <div style="margin-top: 30px; padding: 20px; background: rgba(94,92,230,0.08); border-radius: 12px; border-left: 4px solid #5E5CE6;">
                            <h4 style="color: #60a5fa; margin-bottom: 15px; font-size: 1.1rem;">üí° Key Observations</h4>
                            <ul style="color: #cbd5e1; font-size: 0.9rem; line-height: 1.8; padding-left: 20px;">
                                <li><strong>GPT-OSS-120B dominates</strong>: Achieves 7.5x higher throughput than DeepSeek models with W4A8 quantization</li>
                                <li><strong>CUTLASS vs TRT-LLM</strong>: CUTLASS shows significant advantage for GPT-OSS-120B (+31.9%), but minimal difference for Qwen3 (+1.6%)</li>
                                <li><strong>Model size impact</strong>: Larger models (DeepSeek 671B, Qwen 235B) show dramatically lower per-GPU throughput vs GPT-OSS-120B (120B)</li>
                                <li><strong>Round Robin benefits</strong>: All models gain 11-20% throughput improvement with Round Robin, with DeepSeek-R1 showing highest gain (+20.1%)</li>
                                <li><strong>DeepGeMM backend</strong>: Required for ultra-large models (DeepSeek), performs comparably to CUTLASS/TRT-LLM for similar-sized models</li>
                            </ul>
                        </div>

                        <!-- MoE Expert Load Balance Heatmap -->
                        <div style="margin-top: 40px;">
                            <h3 style="color: #60a5fa; margin-bottom: 20px; font-size: 1.5rem;">MoE Expert Load Balance Analysis</h3>
                            <div style="background: rgba(20, 20, 22, 0.6); border: 1px solid rgba(94, 92, 230, 0.2); border-radius: 16px; padding: 30px; backdrop-filter: blur(10px);">
                                <img src="./images/step000_heatmap.png" alt="MoE Expert Load Distribution Heatmap - Random Dataset" style="max-width: 100%; width: 100%; height: auto; border-radius: 12px; box-shadow: 0 6px 30px rgba(0,0,0,0.5); margin: 0 auto; display: block;">
                                <p style="text-align: center; color: #8E8E93; margin-top: 20px; font-style: italic; font-size: 0.95rem; max-width: 900px; margin-left: auto; margin-right: auto;">
                                    <strong>Figure:</strong> Expert load distribution heatmap for <strong style="color: #60a5fa;">GPT-OSS-120B</strong> on Random Dataset (1k input / 2k output) showing the routing pattern across MoE layers. The visualization reveals load imbalance issues where certain experts receive disproportionate token assignments, leading to performance bottlenecks. Darker regions indicate higher load concentration, while lighter areas show underutilized experts.
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- openMath Dataset Content -->
        <div id="openmath-content" class="dataset-content">
            <!-- Hero Results for openMath Dataset -->
            <!-- <div class="hero-results">
                <div class="result-card winner">
                    <h3>
                        nvidia/openMath Dataset
                        <span class="winner-badge">Math Reasoning</span>
                    </h3>
                    <div class="result-metric">
                        <span class="metric-label">Dataset Type</span>
                        <span class="metric-value">Math Problems (8k Output)</span>
                    </div>
                    <div class="result-metric">
                        <span class="metric-label">Max New Tokens</span>
                        <span class="metric-value highlight">8192 (GPT-OSS-120B)</span>
                    </div>
                    <div class="result-metric">
                        <span class="metric-label">Best Model (8 GPU)</span>
                        <span class="metric-value highlight">GPT-OSS-120B: 32,565 tok/s/gpu</span>
                    </div>
                    <div class="result-metric">
                        <span class="metric-label">Best Backend</span>
                        <span class="metric-value">CUTLASS (W4A8 Quantization)</span>
                    </div>
                    <div class="result-metric">
                        <span class="metric-label">Max Batch Size Per GPU</span>
                        <span class="metric-value">640</span>
                    </div>
                </div>

                <div class="result-card">
                    <h3>
                        ‚ö° Round Robin Impact
                        <span class="winner-badge">Load Balance Analysis</span>
                    </h3>
                    <div class="result-metric">
                        <span class="metric-label">GPT-OSS (8 GPU, CUTLASS)</span>
                        <span class="metric-value" style="color: #10b981;">+9.4% with Round Robin</span>
                    </div>
                    <div class="result-metric">
                        <span class="metric-label">GPT-OSS (8 GPU, TRT-LLM)</span>
                        <span class="metric-value" style="color: #10b981;">+11.1% with Round Robin</span>
                    </div>
                    <div class="result-metric">
                        <span class="metric-label">DeepSeek-V3 (8 GPU)</span>
                        <span class="metric-value" style="color: #10b981;">+6.4% with Round Robin</span>
                    </div>
                    <div class="result-metric">
                        <span class="metric-label">Qwen3-235B (8 GPU)</span>
                        <span class="metric-value" style="color: #10b981;">+7.2% with Round Robin</span>
                    </div>
                </div>
            </div> -->

            <!-- openMath Charts and Analysis -->
            <div class="section">
                <h2>nvidia/openMath: Multi-Model Performance Analysis</h2>
                
                <!-- GPT-OSS-120B Throughput Chart -->
                <div class="chart-container">
                    <h3>GPT-OSS-120B Throughput Scaling (Higher is Better)</h3>
                    <div class="chart-wrapper">
                        <canvas id="openmath-gpt-throughput-chart"></canvas>
                    </div>
                </div>

                <!-- GPT-OSS-120B Latency Chart -->
                <!-- <div class="chart-container">
                    <h3>GPT-OSS-120B Latency Scaling (Lower is Better)</h3>
                    <div class="chart-wrapper">
                        <canvas id="openmath-gpt-latency-chart"></canvas>
                    </div>
                </div> -->

                <!-- Multi-Model Comparison -->
                <div class="chart-container">
                    <h3>8-GPU Multi-Model Throughput Comparison</h3>
                    <div class="chart-wrapper">
                        <canvas id="openmath-multimodel-chart"></canvas>
                    </div>
                </div>

                <!-- openMath Round Robin Impact Chart -->
                <div class="chart-container">
                    <h3>Round Robin Impact on Throughput (8 GPUs)</h3>
                    <div class="chart-wrapper">
                        <canvas id="openmath-gap-chart"></canvas>
                    </div>
                </div>

                <!-- Performance Tables -->
                <div style="overflow-x: auto; margin-top: 30px;">
                    <!-- <h3>GPT-OSS-120B Detailed Performance (nvidia/openMath Dataset)</h3>
                    <table>
                        <thead>
                            <tr>
                                <th>GPUs</th>
                                <th>MoE Backend</th>
                                <th>Router Type</th>
                                <th>Throughput (tok/s/gpu)</th>
                                <th>Total Latency (ms)</th>
                                <th>Throughput Gap</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>1</td>
                                <td>CUTLASS</td>
                                <td>Round Robin</td>
                                <td class="perf-good">24,221</td>
                                <td>162,346</td>
                                <td class="perf-good">0% (Ideal)</td>
                            </tr>
                            <tr>
                                <td>1</td>
                                <td>CUTLASS</td>
                                <td>Default</td>
                                <td>24,889</td>
                                <td>157,986</td>
                                <td class="perf-good">+2.8%</td>
                            </tr>
                            <tr>
                                <td>2</td>
                                <td>CUTLASS</td>
                                <td>Round Robin</td>
                                <td class="perf-good">29,646</td>
                                <td>132,639</td>
                                <td class="perf-good">0% (Ideal)</td>
                            </tr>
                            <tr>
                                <td>2</td>
                                <td>CUTLASS</td>
                                <td>Default</td>
                                <td>27,839</td>
                                <td>141,247</td>
                                <td class="perf-neutral">-6.1%</td>
                            </tr>
                            <tr class="highlight">
                                <td><strong>4</strong></td>
                                <td><strong>CUTLASS</strong></td>
                                <td><strong>Round Robin</strong></td>
                                <td class="perf-good"><strong>31,206</strong></td>
                                <td><strong>126,008</strong></td>
                                <td class="perf-good"><strong>0% (Ideal)</strong></td>
                            </tr>
                            <tr>
                                <td>4</td>
                                <td>CUTLASS</td>
                                <td>Default</td>
                                <td>28,500</td>
                                <td>137,970</td>
                                <td class="perf-neutral">-8.7%</td>
                            </tr>
                            <tr class="highlight">
                                <td><strong>8</strong></td>
                                <td><strong>CUTLASS</strong></td>
                                <td><strong>Round Robin</strong></td>
                                <td class="perf-good"><strong>32,565</strong></td>
                                <td><strong>120,749</strong></td>
                                <td class="perf-good"><strong>0% (Ideal)</strong></td>
                            </tr>
                            <tr>
                                <td>8</td>
                                <td>CUTLASS</td>
                                <td>Default</td>
                                <td>29,757</td>
                                <td>132,142</td>
                                <td class="perf-bad">-8.6%</td>
                            </tr>
                            <tr>
                                <td>1</td>
                                <td>TRT-LLM</td>
                                <td>Round Robin</td>
                                <td class="perf-neutral">24,067</td>
                                <td>163,387</td>
                                <td class="perf-good">0% (Ideal)</td>
                            </tr>
                            <tr>
                                <td>1</td>
                                <td>TRT-LLM</td>
                                <td>Default</td>
                                <td>22,656</td>
                                <td>173,561</td>
                                <td class="perf-neutral">-5.9%</td>
                            </tr>
                            <tr>
                                <td>2</td>
                                <td>TRT-LLM</td>
                                <td>Round Robin</td>
                                <td class="perf-neutral">28,824</td>
                                <td>136,420</td>
                                <td class="perf-good">0% (Ideal)</td>
                            </tr>
                            <tr>
                                <td>2</td>
                                <td>TRT-LLM</td>
                                <td>Default</td>
                                <td>27,018</td>
                                <td>145,538</td>
                                <td class="perf-neutral">-6.3%</td>
                            </tr>
                            <tr>
                                <td>4</td>
                                <td>TRT-LLM</td>
                                <td>Round Robin</td>
                                <td class="perf-neutral">26,630</td>
                                <td>147,660</td>
                                <td class="perf-good">0% (Ideal)</td>
                            </tr>
                            <tr>
                                <td>4</td>
                                <td>TRT-LLM</td>
                                <td>Default</td>
                                <td>25,387</td>
                                <td>154,886</td>
                                <td class="perf-neutral">-4.7%</td>
                            </tr>
                            <tr>
                                <td>8</td>
                                <td>TRT-LLM</td>
                                <td>Round Robin</td>
                                <td class="perf-neutral">24,967</td>
                                <td>157,492</td>
                                <td class="perf-good">0% (Ideal)</td>
                            </tr>
                            <tr>
                                <td>8</td>
                                <td>TRT-LLM</td>
                                <td>Default</td>
                                <td>22,467</td>
                                <td>175,017</td>
                                <td class="perf-bad">-10.0%</td>
                            </tr>
                        </tbody>
                    </table>

                    <h3 style="margin-top: 60px;">Multi-Model Comparison (8 GPUs, nvidia/openMath)</h3>
                    <table>
                        <thead>
                            <tr>
                                <th>Model</th>
                                <th>Backend</th>
                                <th>Router Type</th>
                                <th>Max Tokens</th>
                                <th>Throughput (tok/s/gpu)</th>
                                <th>Total Latency (ms)</th>
                                <th>Quantization</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr class="highlight" style="background: rgba(16, 185, 129, 0.15);">
                                <td><strong>GPT-OSS-120B</strong></td>
                                <td><strong>CUTLASS</strong></td>
                                <td><strong>Round Robin</strong></td>
                                <td><strong>8192</strong></td>
                                <td class="perf-good"><strong>32,565</strong></td>
                                <td>120,749</td>
                                <td>W4A8_MXFP4_MXFP8</td>
                            </tr>
                            <tr>
                                <td>GPT-OSS-120B</td>
                                <td>CUTLASS</td>
                                <td>Default</td>
                                <td>8192</td>
                                <td>29,757</td>
                                <td>132,142</td>
                                <td>W4A8_MXFP4_MXFP8</td>
                            </tr>
                            <tr>
                                <td>GPT-OSS-120B</td>
                                <td>TRT-LLM</td>
                                <td>Round Robin</td>
                                <td>8192</td>
                                <td>24,967</td>
                                <td>157,492</td>
                                <td>W4A8_MXFP4_MXFP8</td>
                            </tr>
                            <tr>
                                <td>GPT-OSS-120B</td>
                                <td>TRT-LLM</td>
                                <td>Default</td>
                                <td>8192</td>
                                <td>22,467</td>
                                <td>175,017</td>
                                <td>W4A8_MXFP4_MXFP8</td>
                            </tr>
                            <tr class="highlight" style="background: rgba(239, 68, 68, 0.15);">
                                <td><strong>DeepSeek-V3</strong></td>
                                <td><strong>DeepGeMM</strong></td>
                                <td><strong>Round Robin</strong></td>
                                <td><strong>2048</strong></td>
                                <td class="perf-neutral"><strong>5,154</strong></td>
                                <td>763,005</td>
                                <td>FP8_BLOCK_SCALES</td>
                            </tr>
                            <tr>
                                <td>DeepSeek-V3</td>
                                <td>DeepGeMM</td>
                                <td>Default</td>
                                <td>2048</td>
                                <td>4,844</td>
                                <td>763,005</td>
                                <td>FP8_BLOCK_SCALES</td>
                            </tr>
                            <tr class="highlight" style="background: rgba(168, 85, 247, 0.15);">
                                <td><strong>DeepSeek-R1</strong></td>
                                <td><strong>DeepGeMM</strong></td>
                                <td><strong>Round Robin</strong></td>
                                <td><strong>2048</strong></td>
                                <td class="perf-neutral"><strong>5,124</strong></td>
                                <td>767,473</td>
                                <td>FP8_BLOCK_SCALES</td>
                            </tr>
                            <tr>
                                <td>DeepSeek-R1</td>
                                <td>DeepGeMM</td>
                                <td>Default</td>
                                <td>2048</td>
                                <td>4,802</td>
                                <td>818,796</td>
                                <td>FP8_BLOCK_SCALES</td>
                            </tr>
                            <tr class="highlight" style="background: rgba(245, 158, 11, 0.15);">
                                <td><strong>Qwen3-235B-A22B</strong></td>
                                <td><strong>CUTLASS</strong></td>
                                <td><strong>Round Robin</strong></td>
                                <td><strong>2048</strong></td>
                                <td class="perf-neutral"><strong>5,063</strong></td>
                                <td>776,678</td>
                                <td>N/A</td>
                            </tr>
                            <tr>
                                <td>Qwen3-235B-A22B</td>
                                <td>CUTLASS</td>
                                <td>Default</td>
                                <td>2048</td>
                                <td>4,723</td>
                                <td>832,554</td>
                                <td>N/A</td>
                            </tr>
                            <tr>
                                <td>Qwen3-235B-A22B</td>
                                <td>TRT-LLM</td>
                                <td>Round Robin</td>
                                <td>2048</td>
                                <td>5,059</td>
                                <td>777,266</td>
                                <td>N/A</td>
                            </tr>
                            <tr>
                                <td>Qwen3-235B-A22B</td>
                                <td>TRT-LLM</td>
                                <td>Default</td>
                                <td>2048</td>
                                <td>4,724</td>
                                <td>832,398</td>
                                <td>N/A</td>
                            </tr>
                        </tbody>
                    </table> -->

                    <div style="margin-top: 30px; padding: 20px; background: rgba(94,92,230,0.08); border-radius: 12px; border-left: 4px solid #5E5CE6;">
                        <h4 style="color: #60a5fa; margin-bottom: 15px; font-size: 1.1rem;">üí° Key Observations (openMath Dataset)</h4>
                        <ul style="color: #cbd5e1; font-size: 0.9rem; line-height: 1.8; padding-left: 20px;">
                            <li><strong>GPT-OSS-120B achieves exceptional performance</strong>: 32,565 tok/s/gpu at 8 GPUs with Round Robin - 6.3x higher than DeepSeek models despite longer output sequence (8192 vs 2048 tokens)</li>
                            <li><strong>Longer output sequences boost throughput</strong>: GPT-OSS shows 40-68% higher per-GPU throughput with 8k outputs vs 2k outputs on Random/ShareGPT datasets, demonstrating memory-bound decode efficiency</li>
                            <li><strong>Round Robin shows consistent 6-11% gains</strong>: All models benefit from perfect routing, with TRT-LLM showing slightly higher improvement (10-11%) vs CUTLASS (6-9%)</li>
                            <li><strong>CUTLASS maintains advantage</strong>: For GPT-OSS-120B, CUTLASS outperforms TRT-LLM by 30-45% across all GPU counts, confirming backend superiority for this model</li>
                            <li><strong>Scaling efficiency improves with load</strong>: Unlike 2k-output workloads that peak at 4 GPUs, the 8k-output math workload shows continued throughput growth to 8 GPUs (32,565 tok/s/gpu), suggesting better amortization of communication overhead with longer decode phases</li>
                            <li><strong>DeepSeek and Qwen show parity</strong>: All three large models (DeepSeek-V3, DeepSeek-R1, Qwen3-235B) achieve similar ~5k tok/s/gpu with Round Robin, indicating model size is the primary bottleneck</li>
                        </ul>
                    </div>

                    <!-- MoE Expert Load Balance Heatmap -->
                    <div style="margin-top: 40px;">
                        <h3 style="color: #60a5fa; margin-bottom: 20px; font-size: 1.5rem;">MoE Expert Load Balance Analysis</h3>
                        <div style="background: rgba(20, 20, 22, 0.6); border: 1px solid rgba(94, 92, 230, 0.2); border-radius: 16px; padding: 30px; backdrop-filter: blur(10px);">
                            <img src="./images/step030_heatmap.png" alt="MoE Expert Load Distribution Heatmap" style="max-width: 100%; width: 100%; height: auto; border-radius: 12px; box-shadow: 0 6px 30px rgba(0,0,0,0.5); margin: 0 auto; display: block;">
                            <p style="text-align: center; color: #8E8E93; margin-top: 20px; font-style: italic; font-size: 0.95rem; max-width: 900px; margin-left: auto; margin-right: auto;">
                                <strong>Figure:</strong> Expert load distribution heatmap for <strong style="color: #60a5fa;">GPT-OSS-120B</strong> showing the routing pattern across MoE layers. The visualization reveals load imbalance issues where certain experts receive disproportionate token assignments, leading to performance bottlenecks. Darker regions indicate higher load concentration, while lighter areas show underutilized experts.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Key Insights Section -->
        <div class="insights-section">
            <h2>Insights</h2>
            <div class="insights-grid">
                <div class="insight-card">
                    <h3>üìä Conclusion</h3>
                    
                    <div class="conclusion-intro">
                        <p>As the <strong>number of GPUs</strong> and <strong>EP size</strong> increase, the <strong>MoE load‚Äëbalancing problem becomes more severe</strong>.</p>
                    </div>
                    
                    <div class="insight-section-group">
                        <h4 class="insight-subsection-title">üìà Performance Degradation</h4>
                        <ul class="insight-list">
                            <li><strong>Throughput gap grows</strong> with scale ‚Äî on GSM8K the gap widens from ~2‚Äì3% at EP=4 to ~8‚Äì11% at EP=8</li>
                            <li><strong>Latency gap also increases</strong> ‚Äî from ~1.5‚Äì3.2% at EP=2‚Äì4 to ~8‚Äì12% at EP=8</li>
                            <li>Primary contributors: heavier all‚Äëto‚Äëall traffic, router skew, and per‚Äëexpert queuing/overflow</li>
                        </ul>
                    </div>
                    
                    <div class="insight-section-group">
                        <h4 class="insight-subsection-title">üí° Practical Mitigations</h4>
                        <ul class="insight-list">
                            <li>Tune auxiliary load‚Äëbalancing loss and capacity factor; consider dropless routing when feasible</li>
                            <li><strong>Speculative decoding‚Äìbased expert prefetch</strong>: use a lightweight drafter to predict token‚Äëto‚Äëexpert routes, prefetch the top‚Äëk ‚Äúhot‚Äù experts ahead of verification, and cap overfetch with a cutoff policy.</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <div id="customTooltip" class="custom-tooltip">
        <div class="tooltip-title"></div>
        <div class="tooltip-content"></div>
        <div class="tooltip-gap"></div>
    </div>

    <script>
        // Dataset switching function
        function switchDataset(dataset) {
            // Update tab buttons
            const tabs = document.querySelectorAll('.tab-button');
            tabs.forEach(tab => tab.classList.remove('active'));
            event.target.classList.add('active');
            
            // Update content
            const contents = document.querySelectorAll('.dataset-content');
            contents.forEach(content => content.classList.remove('active'));
            document.getElementById(`${dataset}-content`).classList.add('active');
        }

        // Copy to Clipboard
        function copyToClipboard(event) {
            event.preventDefault();
            const button = event.target;
            const codeBlock = button.closest('.code-block');
            
            // Check if it's a textarea or code element
            const textarea = codeBlock.querySelector('textarea');
            const codeText = textarea ? textarea.value : codeBlock.querySelector('code').textContent;
            
            navigator.clipboard.writeText(codeText).then(() => {
                const originalText = button.textContent;
                button.textContent = '‚úÖ Copied!';
                button.classList.add('copied');
                
                setTimeout(() => {
                    button.textContent = originalText;
                    button.classList.remove('copied');
                }, 2000);
            }).catch(err => {
                console.error('Copy failed:', err);
                button.textContent = '‚ùå Failed';
            });
        }
        
        // Auto-resize textareas
        document.addEventListener('DOMContentLoaded', function() {
            document.querySelectorAll('.code-block textarea').forEach(textarea => {
                textarea.style.height = 'auto';
                textarea.style.height = textarea.scrollHeight + 'px';
            });
        });
        
        // Toggle Section Expand/Collapse
        function toggleSection(header) {
            // Find the closest .command-section parent
            const section = header.closest('.command-section');
            // Find the first .section-content inside this section
            const content = section.querySelector('.section-content');
            const toggleIcon = header.querySelector('.toggle-icon');
            if (content) {
                content.classList.toggle('collapsed');
            }
            if (toggleIcon) {
                toggleIcon.classList.toggle('collapsed');
            }
        }

        // Chart configuration with custom tooltips
        document.addEventListener('DOMContentLoaded', function() {
            // Common chart options
            const commonOptions = {
                responsive: true,
                maintainAspectRatio: false,
                interaction: {
                    mode: 'point',
                    intersect: false
                },
                plugins: {
                    legend: {
                        labels: {
                            color: '#e2e8f0',
                            font: {
                                size: 14,
                                weight: '600'
                            }
                        }
                    },
                    tooltip: {
                        enabled: true
                    }
                },
                scales: {
                    x: {
                        grid: {
                            color: 'rgba(71, 85, 105, 0.2)',
                            borderDash: [3, 3]
                        },
                        ticks: {
                            color: '#e2e8f0',
                            font: {
                                size: 18
                            }
                        },
                        title: {
                            display: true,
                            text: 'EP Size',
                            color: '#e2e8f0',
                            font: {
                                size: 12,
                                weight: '600'
                            }
                        }
                    },
                    y: {
                        grid: {
                            color: 'rgba(71, 85, 105, 0.2)',
                            borderDash: [3, 3]
                        },
                        ticks: {
                            color: '#e2e8f0',
                            font: {
                                size: 16
                            }
                        },
                        title: {
                            display: true,
                            color: '#e2e8f0',
                            font: {
                                size: 12,
                                weight: '600'
                            }
                        }
                    }
                }
            };

            // GSM8K Latency Chart
            const gsm8kLatencyCtx = document.getElementById('gsm8k-latency-chart');
            if (gsm8kLatencyCtx) {
                const gsm8kLatencyOptions = JSON.parse(JSON.stringify(commonOptions));
                gsm8kLatencyOptions.scales.y.title.text = 'Total Latency (s) - Lower is Better';
                
                new Chart(gsm8kLatencyCtx, {
                    type: 'line',
                    data: {
                        labels: ['1', '2', '4', '8'],
                        datasets: [
                            {
                                label: 'CUTLASS Ideal',
                                // added 1-GPU result (7871.9037 ms -> 7.8719 s)
                                data: [7.8719, 8.65, 14.68, 7.90],
                                borderColor: '#10b981',
                                backgroundColor: 'rgba(16, 185, 129, 0.1)',
                                borderWidth: 3,
                                borderDash: [8, 4],
                                tension: 0.2,
                                pointRadius: 5,
                                pointHoverRadius: 8,
                                pointBackgroundColor: '#10b981',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'CUTLASS Actual',
                                // added 1-GPU result (8251.961 ms -> 8.2520 s)
                                data: [8.2520, 8.78, 15.00, 8.53],
                                borderColor: '#f59e0b',
                                backgroundColor: 'rgba(245, 158, 11, 0.1)',
                                borderWidth: 3,
                                tension: 0.2,
                                pointRadius: 5,
                                pointHoverRadius: 8,
                                pointBackgroundColor: '#f59e0b',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'TRTLLM Ideal',
                                // added 1-GPU result (7727.1298 ms -> 7.7271 s)
                                data: [7.7271, 8.69, 14.75, 9.44],
                                borderColor: '#60a5fa',
                                backgroundColor: 'rgba(96, 165, 250, 0.1)',
                                borderWidth: 3,
                                borderDash: [8, 4],
                                tension: 0.2,
                                pointRadius: 5,
                                pointHoverRadius: 8,
                                pointBackgroundColor: '#60a5fa',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'TRTLLM Actual',
                                // added 1-GPU result (7593.6004 ms -> 7.5936 s)
                                data: [7.5936, 8.86, 15.22, 10.59],
                                borderColor: '#ef4444',
                                backgroundColor: 'rgba(239, 68, 68, 0.1)',
                                borderWidth: 3,
                                tension: 0.2,
                                pointRadius: 5,
                                pointHoverRadius: 8,
                                pointBackgroundColor: '#ef4444',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            }
                        ]
                    },
                    options: gsm8kLatencyOptions
                });
            }

            // GSM8K Throughput Chart
            const gsm8kThroughputCtx = document.getElementById('gsm8k-throughput-chart');
            if (gsm8kThroughputCtx) {
                const gsm8kThroughputOptions = JSON.parse(JSON.stringify(commonOptions));
                gsm8kThroughputOptions.scales.y.title.text = 'Throughput (tokens/s/GPU) - Higher is Better';
                
                new Chart(gsm8kThroughputCtx, {
                    type: 'line',
                    data: {
                        labels: ['1', '2', '4', '8'],
                        datasets: [
                            {
                                label: 'CUTLASS Ideal',
                                // added 1-GPU result: 18304.34 tok/s/gpu
                                data: [18304.34, 14437.10, 15968.47, 11553.53],
                                borderColor: '#10b981',
                                backgroundColor: 'rgba(16, 185, 129, 0.1)',
                                borderWidth: 3,
                                borderDash: [8, 4],
                                tension: 0.2,
                                pointRadius: 5,
                                pointHoverRadius: 8,
                                pointBackgroundColor: '#10b981',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'CUTLASS Actual',
                                // added 1-GPU result: 17461.30 tok/s/gpu
                                data: [17461.30, 14216.19, 15622.13, 10699.03],
                                borderColor: '#f59e0b',
                                backgroundColor: 'rgba(245, 158, 11, 0.1)',
                                borderWidth: 3,
                                tension: 0.2,
                                pointRadius: 5,
                                pointHoverRadius: 8,
                                pointBackgroundColor: '#f59e0b',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'TRTLLM Ideal',
                                // added 1-GPU result: 18647.29 tok/s/gpu
                                data: [18647.29, 14377.10, 15886.68, 9666.57],
                                borderColor: '#60a5fa',
                                backgroundColor: 'rgba(96, 165, 250, 0.1)',
                                borderWidth: 3,
                                borderDash: [8, 4],
                                tension: 0.2,
                                pointRadius: 5,
                                pointHoverRadius: 8,
                                pointBackgroundColor: '#60a5fa',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'TRTLLM Actual',
                                // added 1-GPU result: 18975.19 tok/s/gpu
                                data: [18975.19, 14098.34, 15397.04, 8616.56],
                                borderColor: '#ef4444',
                                backgroundColor: 'rgba(239, 68, 68, 0.1)',
                                borderWidth: 3,
                                tension: 0.2,
                                pointRadius: 5,
                                pointHoverRadius: 8,
                                pointBackgroundColor: '#ef4444',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            }
                        ]
                    },
                    options: gsm8kThroughputOptions
                });
            }

            // ShareGPT Model Comparison Chart (8 GPUs)
            const sharegptModelComparisonCtx = document.getElementById('sharegpt-model-comparison-chart');
            if (sharegptModelComparisonCtx) {
                const modelComparisonOptions = JSON.parse(JSON.stringify(commonOptions));
                modelComparisonOptions.scales.y.title.text = 'Output Throughput (tok/s/gpu)';
                modelComparisonOptions.indexAxis = 'y';
                
                new Chart(sharegptModelComparisonCtx, {
                    type: 'bar',
                    data: {
                        labels: ['GPT-OSS-120B\n(Round Robin)', 'GPT-OSS-120B\n(Default)', 'GPT-OSS-120B\n(TRT-LLM Perfect)', 'GPT-OSS-120B\n(TRT-LLM Default)', 'DeepSeek-V3\n(Round Robin)', 'DeepSeek-V3\n(Default)', 'DeepSeek-R1\n(Round Robin)', 'DeepSeek-R1\n(Default)', 'Qwen3-235B\n(Round Robin)', 'Qwen3-235B\n(Default)'],
                        datasets: [{
                            label: 'Throughput (tok/s/gpu)',
                            data: [23702, 22051, 17739, 16425, 3061, 2712, 3111, 2854, 1426, 1358],
                            backgroundColor: [
                                'rgba(16, 185, 129, 0.8)',   // GPT Perfect
                                'rgba(16, 185, 129, 0.5)',   // GPT Default
                                'rgba(96, 165, 250, 0.8)',   // GPT TRT Perfect
                                'rgba(96, 165, 250, 0.5)',   // GPT TRT Default
                                'rgba(239, 68, 68, 0.8)',    // DeepSeek-V3 Perfect
                                'rgba(239, 68, 68, 0.5)',    // DeepSeek-V3 Default
                                'rgba(168, 85, 247, 0.8)',   // DeepSeek-R1 Perfect
                                'rgba(168, 85, 247, 0.5)',   // DeepSeek-R1 Default
                                'rgba(245, 158, 11, 0.8)',   // Qwen Perfect
                                'rgba(245, 158, 11, 0.5)'    // Qwen Default
                            ],
                            borderColor: [
                                '#10b981', '#10b981',
                                '#60a5fa', '#60a5fa',
                                '#ef4444', '#ef4444',
                                '#a855f7', '#a855f7',
                                '#f59e0b', '#f59e0b'
                            ],
                            borderWidth: 2
                        }]
                    },
                    options: {
                        ...modelComparisonOptions,
                        indexAxis: 'y',
                        scales: {
                            x: {
                                ...modelComparisonOptions.scales.y,
                                title: {
                                    display: true,
                                    text: 'Output Throughput (tok/s/gpu)',
                                    color: '#e2e8f0',
                                    font: { size: 12, weight: '600' }
                                }
                            },
                            y: {
                                ...modelComparisonOptions.scales.x,
                                title: { display: false }
                            }
                        }
                    }
                });
            }

            // ShareGPT Round Robin Impact Chart
            const sharegptPerfectRouterCtx = document.getElementById('sharegpt-perfect-router-chart');
            if (sharegptPerfectRouterCtx) {
                const perfectRouterOptions = JSON.parse(JSON.stringify(commonOptions));
                perfectRouterOptions.scales.y.title.text = 'Throughput Improvement (%)';
                
                new Chart(sharegptPerfectRouterCtx, {
                    type: 'bar',
                    data: {
                        labels: ['GPT-OSS\nCUTLASS', 'GPT-OSS\nTRT-LLM', 'DeepSeek-V3\n(8 GPU)', 'DeepSeek-V3\n(7 GPU)', 'DeepSeek-R1', 'Qwen3-235B'],
                        datasets: [{
                            label: 'Performance Gain (%)',
                            data: [
                                ((23702 - 22051) / 22051 * 100).toFixed(1),  // GPT CUTLASS: 7.5%
                                ((17739 - 16425) / 16425 * 100).toFixed(1),  // GPT TRT-LLM: 8.0%
                                ((3061 - 2712) / 2712 * 100).toFixed(1),     // DeepSeek-V3 8GPU: 12.9%
                                ((3409 - 3178) / 3178 * 100).toFixed(1),     // DeepSeek-V3 7GPU: 7.2%
                                ((3111 - 2854) / 2854 * 100).toFixed(1),     // DeepSeek-R1: 9.0%
                                ((1426 - 1358) / 1358 * 100).toFixed(1)      // Qwen3: 5.0%
                            ],
                            backgroundColor: [
                                'rgba(16, 185, 129, 0.7)',
                                'rgba(96, 165, 250, 0.7)',
                                'rgba(239, 68, 68, 0.7)',
                                'rgba(239, 68, 68, 0.5)',
                                'rgba(168, 85, 247, 0.7)',
                                'rgba(245, 158, 11, 0.7)'
                            ],
                            borderColor: [
                                '#10b981',
                                '#60a5fa',
                                '#ef4444',
                                '#ef4444',
                                '#a855f7',
                                '#f59e0b'
                            ],
                            borderWidth: 2
                        }]
                    },
                    options: perfectRouterOptions
                });
            }

            // ShareGPT Throughput Chart
            const sharegptThroughputCtx = document.getElementById('sharegpt-throughput-chart');
            if (sharegptThroughputCtx) {
                const sharegptThroughputOptions = JSON.parse(JSON.stringify(commonOptions));
                sharegptThroughputOptions.scales.y.title.text = 'Throughput (tokens/s/GPU) - Higher is Better';
                
                new Chart(sharegptThroughputCtx, {
                    type: 'line',
                    data: {
                        labels: ['1', '2', '4', '8'],
                        datasets: [
                            {
                                label: 'CUTLASS Ideal',
                                data: [14884, 19686, 23248, 23702],
                                borderColor: '#10b981',
                                backgroundColor: 'rgba(16, 185, 129, 0.1)',
                                borderWidth: 3,
                                borderDash: [8, 4],
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#10b981',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'CUTLASS Actual',
                                data: [15389, 18783, 21768, 22051],
                                borderColor: '#f59e0b',
                                backgroundColor: 'rgba(245, 158, 11, 0.1)',
                                borderWidth: 3,
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#f59e0b',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'TRT-LLM Ideal',
                                data: [14512, 18507, 19378, 17739],
                                borderColor: '#60a5fa',
                                backgroundColor: 'rgba(96, 165, 250, 0.1)',
                                borderWidth: 3,
                                borderDash: [8, 4],
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#60a5fa',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'TRT-LLM Actual',
                                data: [14093, 17595, 18958, 16425],
                                borderColor: '#ef4444',
                                backgroundColor: 'rgba(239, 68, 68, 0.1)',
                                borderWidth: 3,
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#ef4444',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            }
                        ]
                    },
                    options: sharegptThroughputOptions
                });
            }

            // ShareGPT Latency Chart
            const sharegptLatencyCtx = document.getElementById('sharegpt-latency-chart');
            if (sharegptLatencyCtx) {
                const sharegptLatencyOptions = JSON.parse(JSON.stringify(commonOptions));
                sharegptLatencyOptions.scales.y.title.text = 'Total Latency (s) - Lower is Better';
                
                new Chart(sharegptLatencyCtx, {
                    type: 'line',
                    data: {
                        labels: ['1', '2', '4', '8'],
                        datasets: [
                            {
                                label: 'CUTLASS Ideal',
                                data: [264.18, 199.74, 169.14, 165.90],
                                borderColor: '#10b981',
                                backgroundColor: 'rgba(16, 185, 129, 0.1)',
                                borderWidth: 3,
                                borderDash: [8, 4],
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#10b981',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'CUTLASS Actual',
                                data: [255.52, 209.35, 180.64, 178.32],
                                borderColor: '#f59e0b',
                                backgroundColor: 'rgba(245, 158, 11, 0.1)',
                                borderWidth: 3,
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#f59e0b',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'TRT-LLM Ideal',
                                data: [270.97, 212.47, 202.92, 221.66],
                                borderColor: '#60a5fa',
                                backgroundColor: 'rgba(96, 165, 250, 0.1)',
                                borderWidth: 3,
                                borderDash: [8, 4],
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#60a5fa',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'TRT-LLM Actual',
                                data: [279.01, 223.48, 207.42, 239.40],
                                borderColor: '#ef4444',
                                backgroundColor: 'rgba(239, 68, 68, 0.1)',
                                borderWidth: 3,
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#ef4444',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            }
                        ]
                    },
                    options: sharegptLatencyOptions
                });
            }

            // Random Dataset Scaling Chart
            const randomScalingCtx = document.getElementById('random-scaling-chart');
            if (randomScalingCtx) {
                const randomScalingOptions = JSON.parse(JSON.stringify(commonOptions));
                randomScalingOptions.scales.x.title.text = 'Number of GPUs';
                randomScalingOptions.scales.y.title.text = 'Throughput per GPU (tokens/s)';
                
                new Chart(randomScalingCtx, {
                    type: 'line',
                    data: {
                        labels: ['1', '2', '4', '8'],
                        datasets: [
                            {
                                label: 'CUTLASS Ideal',
                                data: [14902.7639, 19702, 23277, 23696],
                                borderColor: '#10b981',
                                backgroundColor: 'rgba(16, 185, 129, 0.1)',
                                borderWidth: 3,
                                borderDash: [8, 4],
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#10b981',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'CUTLASS Actual',
                                data: [15795, 18550, 20859, 19355],
                                borderColor: '#f59e0b',
                                backgroundColor: 'rgba(245, 158, 11, 0.1)',
                                borderWidth: 3,
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#f59e0b',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'TRTLLM Ideal',
                                data: [14530.8435, 18582, 19639, 17665],
                                borderColor: '#60a5fa',
                                backgroundColor: 'rgba(96, 165, 250, 0.1)',
                                borderWidth: 3,
                                borderDash: [8, 4],
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#60a5fa',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'TRTLLM Actual',
                                data: [14256, 17161, 18051, 14678],
                                borderColor: '#ef4444',
                                backgroundColor: 'rgba(239, 68, 68, 0.1)',
                                borderWidth: 3,
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#ef4444',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            }
                        ]
                    },
                    options: randomScalingOptions
                });
            }

            // Random Dataset Latency Scaling Chart
            const randomLatencyScalingCtx = document.getElementById('random-latency-scaling-chart');
            if (randomLatencyScalingCtx) {
                const randomScalingOptions = JSON.parse(JSON.stringify(commonOptions));
                randomScalingOptions.scales.x.title.text = 'Number of GPUs';
                randomScalingOptions.scales.y.title.text = 'Total Latency (ms)';
                
                new Chart(randomLatencyScalingCtx, {
                    type: 'line',
                    data: {
                        labels: ['1', '2', '4', '8'],
                        datasets: [
                            {
                                label: 'CUTLASS Ideal',
                                data: [263.854, 199.580, 168.929, 168.929],
                                borderColor: '#10b981',
                                backgroundColor: 'rgba(16, 185, 129, 0.1)',
                                borderWidth: 3,
                                borderDash: [8, 4],
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#10b981',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'CUTLASS Actual',
                                data: [248.956, 211.977, 188.509, 188.509],
                                borderColor: '#f59e0b',
                                backgroundColor: 'rgba(245, 158, 11, 0.1)',
                                borderWidth: 3,
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#f59e0b',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'TRTLLM Ideal',
                                data: [270.607, 211.616, 200.225, 200.225],
                                borderColor: '#60a5fa',
                                backgroundColor: 'rgba(96, 165, 250, 0.1)',
                                borderWidth: 3,
                                borderDash: [8, 4],
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#60a5fa',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'TRTLLM Actual',
                                data: [275.824, 229.135, 217.835, 217.835],
                                borderColor: '#ef4444',
                                backgroundColor: 'rgba(239, 68, 68, 0.1)',
                                borderWidth: 3,
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#ef4444',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            }
                        ]
                    },
                    options: randomScalingOptions
                });
            }

            // Expert Parallelism Latency Chart
            const epLatencyCtx = document.getElementById('ep-latency-chart');
            if (epLatencyCtx) {
                const epOptions = JSON.parse(JSON.stringify(commonOptions));
                epOptions.scales.y.title.text = 'Total Latency (ms)';
                
                new Chart(epLatencyCtx, {
                    type: 'bar',
                    data: {
                        labels: ['8 GPUs', '4 GPUs', '2 GPUs'],
                        datasets: [
                            {
                                label: 'CUTLASS Open EP',
                                data: [203156.85, 188508.83, 211976.65],
                                backgroundColor: 'rgba(16, 185, 129, 0.7)',
                                borderColor: '#10b981',
                                borderWidth: 2
                            },
                            {
                                label: 'CUTLASS Closed EP',
                                data: [265061.79, 209314.52, 227963.58],
                                backgroundColor: 'rgba(245, 158, 11, 0.7)',
                                borderColor: '#f59e0b',
                                borderWidth: 2
                            },
                            {
                                label: 'TRTLLM Open EP',
                                data: [267898.03, 217835.41, 229135.21],
                                backgroundColor: 'rgba(96, 165, 250, 0.7)',
                                borderColor: '#60a5fa',
                                borderWidth: 2
                            },
                            {
                                label: 'TRTLLM Closed EP',
                                data: [231924.01, 191022.23, 218822.20],
                                backgroundColor: 'rgba(239, 68, 68, 0.7)',
                                borderColor: '#ef4444',
                                borderWidth: 2
                            }
                        ]
                    },
                    options: epOptions
                });
            }

            // Fixed Concurrency Throughput Chart
            const fixedConcurrencyCtx = document.getElementById('fixed-concurrency-throughput-chart');
            if (fixedConcurrencyCtx) {
                const fixedConcurrencyOptions = JSON.parse(JSON.stringify(commonOptions));
                fixedConcurrencyOptions.scales.x.title.text = 'Number of GPUs';
                fixedConcurrencyOptions.scales.y.title.text = 'Output Throughput/GPU (tok/s)';
                
                new Chart(fixedConcurrencyCtx, {
                    type: 'line',
                    data: {
                        labels: ['1', '2', '4', '8'],
                        datasets: [
                            {
                                label: 'CUTLASS (Round Robin)',
                                data: [16370.73, 21741.91, 23449.79, 23816.31],
                                borderColor: '#10b981',
                                backgroundColor: 'rgba(16, 185, 129, 0.1)',
                                borderWidth: 3,
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#10b981',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'CUTLASS (Default Router)',
                                data: [16667.98, 20244.72, 21015.80, 19358.87],
                                borderColor: '#f59e0b',
                                backgroundColor: 'rgba(245, 158, 11, 0.1)',
                                borderWidth: 3,
                                borderDash: [5, 5],
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#f59e0b',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'TRTLLM (Round Robin)',
                                data: [null, 19891.90, 19736.75, 17664.95],
                                borderColor: '#60a5fa',
                                backgroundColor: 'rgba(96, 165, 250, 0.1)',
                                borderWidth: 3,
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#60a5fa',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'TRTLLM (Default Router)',
                                data: [null, 18347.52, 18161.90, 14535.98],
                                borderColor: '#ef4444',
                                backgroundColor: 'rgba(239, 68, 68, 0.1)',
                                borderWidth: 3,
                                borderDash: [5, 5],
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#ef4444',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            }
                        ]
                    },
                    options: fixedConcurrencyOptions
                });
            }

            // Expert Parallelism Throughput Chart
            const epThroughputCtx = document.getElementById('ep-throughput-chart');
            if (epThroughputCtx) {
                const epOptions = JSON.parse(JSON.stringify(commonOptions));
                epOptions.scales.y.title.text = 'Output Throughput/GPU (tok/s)';
                
                new Chart(epThroughputCtx, {
                    type: 'bar',
                    data: {
                        labels: ['8 GPUs', '4 GPUs', '2 GPUs'],
                        datasets: [
                            {
                                label: 'CUTLASS Open EP',
                                data: [19355.29, 20859.29, 18549.97],
                                backgroundColor: 'rgba(16, 185, 129, 0.7)',
                                borderColor: '#10b981',
                                borderWidth: 2
                            },
                            {
                                label: 'CUTLASS Closed EP',
                                data: [14834.88, 18785.89, 17249.07],
                                backgroundColor: 'rgba(245, 158, 11, 0.7)',
                                borderColor: '#f59e0b',
                                borderWidth: 2
                            },
                            {
                                label: 'TRTLLM Open EP',
                                data: [14677.82, 18051.06, 17160.87],
                                backgroundColor: 'rgba(96, 165, 250, 0.7)',
                                borderColor: '#60a5fa',
                                borderWidth: 2
                            },
                            {
                                label: 'TRTLLM Closed EP',
                                data: [16954.52, 20584.83, 17969.66],
                                backgroundColor: 'rgba(239, 68, 68, 0.7)',
                                borderColor: '#ef4444',
                                borderWidth: 2
                            }
                        ]
                    },
                    options: epOptions
                });
            }

            // Random Dataset Impact Chart (Bar chart showing performance gap)
            const randomImpactCtx = document.getElementById('random-impact-chart');
            if (randomImpactCtx) {
                const randomImpactOptions = JSON.parse(JSON.stringify(commonOptions));
                randomImpactOptions.scales.x.title.text = 'Configuration (GPUs / EP Size)';
                randomImpactOptions.scales.y.title.text = 'Performance Gap from Ideal (%)';
                randomImpactOptions.plugins.tooltip.enabled = true;
                randomImpactOptions.plugins.tooltip.external = null;
                
                new Chart(randomImpactCtx, {
                    type: 'bar',
                    data: {
                        labels: ['1 GPU/EP=1', '2 GPUs/EP=2', '4 GPUs/EP=4', '8 GPUs/EP=8'],
                        datasets: [
                            {
                                label: 'CUTLASS Gap',
                                data: [0, -5.8, -10.4, -18.3],
                                backgroundColor: 'rgba(245, 158, 11, 0.7)',
                                borderColor: '#f59e0b',
                                borderWidth: 2
                            },
                            {
                                label: 'TRTLLM Gap',
                                data: [0, -7.6, -8.1, -16.9],
                                backgroundColor: 'rgba(239, 68, 68, 0.7)',
                                borderColor: '#ef4444',
                                borderWidth: 2
                            }
                        ]
                    },
                    options: randomImpactOptions
                });
            }

            // Random Dataset 8-GPU Multi-Model Comparison Chart
            const random8GpuCtx = document.getElementById('random-8gpu-comparison-chart');
            if (random8GpuCtx) {
                const random8GpuOptions = JSON.parse(JSON.stringify(commonOptions));
                random8GpuOptions.scales.y.title.text = 'Throughput (tokens/s/GPU)';
                random8GpuOptions.plugins.legend.position = 'top';
                
                new Chart(random8GpuCtx, {
                    type: 'bar',
                    data: {
                        labels: ['GPT-OSS-120B', 'Qwen3-235B-A22B', 'DeepSeek-V3', 'DeepSeek-R1'],
                        datasets: [
                            {
                                label: 'CUTLASS / DeepGeMM (Default)',
                                data: [19355, 2897, 2598, 2586],
                                backgroundColor: 'rgba(16, 185, 129, 0.7)',
                                borderColor: '#10b981',
                                borderWidth: 2
                            },
                            {
                                label: 'CUTLASS / DeepGeMM (Round Robin)',
                                data: [23696, 3219, 3081, 3107],
                                backgroundColor: 'rgba(16, 185, 129, 0.9)',
                                borderColor: '#10b981',
                                borderWidth: 2
                            },
                            {
                                label: 'TRT-LLM (Default)',
                                data: [14678, 2851, 0, 0], // DeepSeek uses DeepGeMM only
                                backgroundColor: 'rgba(239, 68, 68, 0.7)',
                                borderColor: '#ef4444',
                                borderWidth: 2
                            },
                            {
                                label: 'TRT-LLM (Round Robin)',
                                data: [17665, 3188, 0, 0], // DeepSeek uses DeepGeMM only
                                backgroundColor: 'rgba(239, 68, 68, 0.9)',
                                borderColor: '#ef4444',
                                borderWidth: 2
                            }
                        ]
                    },
                    options: random8GpuOptions
                });
            }

            // Random Dataset 8-GPU Round Robin Impact Chart
            const random8GpuPerfectRouterCtx = document.getElementById('random-8gpu-perfect-router-chart');
            if (random8GpuPerfectRouterCtx) {
                const perfectRouterOptions = JSON.parse(JSON.stringify(commonOptions));
                perfectRouterOptions.scales.y.title.text = 'Performance Improvement (%)';
                
                new Chart(random8GpuPerfectRouterCtx, {
                    type: 'bar',
                    data: {
                        labels: ['GPT-OSS\nCUTLASS', 'GPT-OSS\nTRT-LLM', 'Qwen3\nCUTLASS', 'Qwen3\nTRT-LLM', 'DeepSeek-V3\nDeepGeMM', 'DeepSeek-R1\nDeepGeMM'],
                        datasets: [{
                            label: 'Throughput Gain with Round Robin (%)',
                            data: [
                                ((23696 - 19355) / 19355 * 100).toFixed(1),  // GPT CUTLASS: +22.4%
                                ((17665 - 14678) / 14678 * 100).toFixed(1),  // GPT TRT-LLM: +20.3%
                                ((3219 - 2897) / 2897 * 100).toFixed(1),     // Qwen3 CUTLASS: +11.1%
                                ((3188 - 2851) / 2851 * 100).toFixed(1),     // Qwen3 TRT-LLM: +11.8%
                                ((3081 - 2598) / 2598 * 100).toFixed(1),     // DeepSeek-V3: +18.6%
                                ((3107 - 2586) / 2586 * 100).toFixed(1)      // DeepSeek-R1: +20.1%
                            ],
                            backgroundColor: [
                                'rgba(16, 185, 129, 0.8)',   // GPT CUTLASS
                                'rgba(96, 165, 250, 0.8)',   // GPT TRT-LLM
                                'rgba(245, 158, 11, 0.8)',   // Qwen3 CUTLASS
                                'rgba(245, 158, 11, 0.6)',   // Qwen3 TRT-LLM
                                'rgba(239, 68, 68, 0.8)',    // DeepSeek-V3
                                'rgba(168, 85, 247, 0.8)'    // DeepSeek-R1
                            ],
                            borderColor: [
                                '#10b981',
                                '#60a5fa',
                                '#f59e0b',
                                '#f59e0b',
                                '#ef4444',
                                '#a855f7'
                            ],
                            borderWidth: 2
                        }]
                    },
                    options: perfectRouterOptions
                });
            }

            // ============= openMath Dataset Charts =============
            
            // openMath GPT-OSS-120B Throughput Chart
            const openmathGptThroughputCtx = document.getElementById('openmath-gpt-throughput-chart');
            if (openmathGptThroughputCtx) {
                const openmathThroughputOptions = JSON.parse(JSON.stringify(commonOptions));
                openmathThroughputOptions.scales.y.title.text = 'Throughput (tokens/s/GPU)';
                
                new Chart(openmathGptThroughputCtx, {
                    type: 'line',
                    data: {
                        labels: ['1', '2', '4', '8'],
                        datasets: [
                            {
                                label: 'CUTLASS (Round Robin)',
                                data: [24221, 29646, 31206, 32565],
                                borderColor: '#10b981',
                                backgroundColor: 'rgba(16, 185, 129, 0.1)',
                                borderWidth: 3,
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#10b981',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'CUTLASS (Default)',
                                data: [24889, 27839, 28500, 29757],
                                borderColor: '#f59e0b',
                                backgroundColor: 'rgba(245, 158, 11, 0.1)',
                                borderWidth: 3,
                                borderDash: [5, 5],
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#f59e0b',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'TRT-LLM (Round Robin)',
                                data: [24067, 28824, 26630, 24967],
                                borderColor: '#60a5fa',
                                backgroundColor: 'rgba(96, 165, 250, 0.1)',
                                borderWidth: 3,
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#60a5fa',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'TRT-LLM (Default)',
                                data: [22656, 27018, 25387, 22467],
                                borderColor: '#ef4444',
                                backgroundColor: 'rgba(239, 68, 68, 0.1)',
                                borderWidth: 3,
                                borderDash: [5, 5],
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#ef4444',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            }
                        ]
                    },
                    options: openmathThroughputOptions
                });
            }

            // openMath GPT-OSS-120B Latency Chart
            const openmathGptLatencyCtx = document.getElementById('openmath-gpt-latency-chart');
            if (openmathGptLatencyCtx) {
                const openmathLatencyOptions = JSON.parse(JSON.stringify(commonOptions));
                openmathLatencyOptions.scales.y.title.text = 'Total Latency (ms)';
                
                new Chart(openmathGptLatencyCtx, {
                    type: 'line',
                    data: {
                        labels: ['1', '2', '4', '8'],
                        datasets: [
                            {
                                label: 'CUTLASS (Round Robin)',
                                data: [162346, 132639, 126008, 120749],
                                borderColor: '#10b981',
                                backgroundColor: 'rgba(16, 185, 129, 0.1)',
                                borderWidth: 3,
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#10b981',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'CUTLASS (Default)',
                                data: [157986, 141247, 137970, 132142],
                                borderColor: '#f59e0b',
                                backgroundColor: 'rgba(245, 158, 11, 0.1)',
                                borderWidth: 3,
                                borderDash: [5, 5],
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#f59e0b',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'TRT-LLM (Round Robin)',
                                data: [163387, 136420, 147660, 157492],
                                borderColor: '#60a5fa',
                                backgroundColor: 'rgba(96, 165, 250, 0.1)',
                                borderWidth: 3,
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#60a5fa',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            },
                            {
                                label: 'TRT-LLM (Default)',
                                data: [173561, 145538, 154886, 175017],
                                borderColor: '#ef4444',
                                backgroundColor: 'rgba(239, 68, 68, 0.1)',
                                borderWidth: 3,
                                borderDash: [5, 5],
                                tension: 0.2,
                                pointRadius: 6,
                                pointHoverRadius: 9,
                                pointBackgroundColor: '#ef4444',
                                pointBorderColor: '#fff',
                                pointBorderWidth: 2
                            }
                        ]
                    },
                    options: openmathLatencyOptions
                });
            }

            // openMath Multi-Model Comparison Chart (8 GPUs)
            const openmathMultimodelCtx = document.getElementById('openmath-multimodel-chart');
            if (openmathMultimodelCtx) {
                const multimodelOptions = JSON.parse(JSON.stringify(commonOptions));
                multimodelOptions.scales.y.title.text = 'Throughput (tokens/s/GPU)';
                multimodelOptions.indexAxis = 'y';
                
                new Chart(openmathMultimodelCtx, {
                    type: 'bar',
                    data: {
                        labels: [
                            'GPT-OSS\n(CUTLASS Perfect)',
                            'GPT-OSS\n(CUTLASS Default)',
                            'GPT-OSS\n(TRT-LLM Perfect)',
                            'GPT-OSS\n(TRT-LLM Default)',
                            'DeepSeek-V3\n(Perfect)',
                            'DeepSeek-V3\n(Default)',
                            'DeepSeek-R1\n(Perfect)',
                            'DeepSeek-R1\n(Default)',
                            'Qwen3-235B\n(CUTLASS Perfect)',
                            'Qwen3-235B\n(CUTLASS Default)',
                            'Qwen3-235B\n(TRT-LLM Perfect)',
                            'Qwen3-235B\n(TRT-LLM Default)'
                        ],
                        datasets: [{
                            label: 'Throughput (tok/s/gpu) @ 8 GPUs',
                            data: [32565, 29757, 24967, 22467, 5154, 4844, 5124, 4802, 5063, 4723, 5059, 4724],
                            backgroundColor: [
                                'rgba(16, 185, 129, 0.9)',    // GPT CUTLASS Perfect
                                'rgba(16, 185, 129, 0.6)',    // GPT CUTLASS Default
                                'rgba(96, 165, 250, 0.9)',    // GPT TRT Perfect
                                'rgba(96, 165, 250, 0.6)',    // GPT TRT Default
                                'rgba(239, 68, 68, 0.9)',     // DeepSeek-V3 Perfect
                                'rgba(239, 68, 68, 0.6)',     // DeepSeek-V3 Default
                                'rgba(168, 85, 247, 0.9)',    // DeepSeek-R1 Perfect
                                'rgba(168, 85, 247, 0.6)',    // DeepSeek-R1 Default
                                'rgba(245, 158, 11, 0.9)',    // Qwen CUTLASS Perfect
                                'rgba(245, 158, 11, 0.6)',    // Qwen CUTLASS Default
                                'rgba(245, 158, 11, 0.8)',    // Qwen TRT Perfect
                                'rgba(245, 158, 11, 0.5)'     // Qwen TRT Default
                            ],
                            borderColor: [
                                '#10b981', '#10b981',
                                '#60a5fa', '#60a5fa',
                                '#ef4444', '#ef4444',
                                '#a855f7', '#a855f7',
                                '#f59e0b', '#f59e0b',
                                '#f59e0b', '#f59e0b'
                            ],
                            borderWidth: 2
                        }]
                    },
                    options: {
                        ...multimodelOptions,
                        indexAxis: 'y',
                        scales: {
                            x: {
                                ...multimodelOptions.scales.y,
                                title: {
                                    display: true,
                                    text: 'Throughput (tokens/s/GPU)',
                                    color: '#e2e8f0',
                                    font: { size: 12, weight: '600' }
                                }
                            },
                            y: {
                                ...multimodelOptions.scales.x,
                                title: { display: false }
                            }
                        }
                    }
                });
            }

            // openMath Round Robin Impact Chart (8 GPUs, Multi-Model Comparison)
            const openmathGapCtx = document.getElementById('openmath-gap-chart');
            if (openmathGapCtx) {
                const gapOptions = JSON.parse(JSON.stringify(commonOptions));
                gapOptions.scales.y.title.text = 'Performance Improvement (%)';

                new Chart(openmathGapCtx, {
                    type: 'bar',
                    data: {
                        labels: ['GPT-OSS\nCUTLASS', 'GPT-OSS\nTRT-LLM', 'DeepSeek-V3\nDeepGeMM', 'DeepSeek-R1\nDeepGeMM', 'Qwen3-235B\nCUTLASS', 'Qwen3-235B\nTRT-LLM'],
                        datasets: [{
                            label: 'Throughput Gain with Round Robin (%)',
                            data: [
                                ((32565 - 29757) / 29757 * 100).toFixed(1),   // GPT-OSS CUTLASS: +9.4%
                                ((24967 - 22467) / 22467 * 100).toFixed(1),   // GPT-OSS TRT-LLM: +11.1%
                                ((5154 - 4844) / 4844 * 100).toFixed(1),      // DeepSeek-V3: +6.4%
                                ((5124 - 4802) / 4802 * 100).toFixed(1),      // DeepSeek-R1: +6.7%
                                ((5063 - 4723) / 4723 * 100).toFixed(1),      // Qwen3 CUTLASS: +7.2%
                                ((5059 - 4724) / 4724 * 100).toFixed(1)       // Qwen3 TRT-LLM: +7.1%
                            ],
                            backgroundColor: [
                                'rgba(16, 185, 129, 0.8)',   // GPT CUTLASS
                                'rgba(96, 165, 250, 0.8)',   // GPT TRT-LLM
                                'rgba(239, 68, 68, 0.8)',    // DeepSeek-V3
                                'rgba(168, 85, 247, 0.8)',   // DeepSeek-R1
                                'rgba(245, 158, 11, 0.8)',   // Qwen3 CUTLASS
                                'rgba(245, 158, 11, 0.6)'    // Qwen3 TRT-LLM
                            ],
                            borderColor: [
                                '#10b981',
                                '#60a5fa',
                                '#ef4444',
                                '#a855f7',
                                '#f59e0b',
                                '#f59e0b'
                            ],
                            borderWidth: 2
                        }]
                    },
                    options: gapOptions
                });
            }

        });
    </script>
</body>
</html>